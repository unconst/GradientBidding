{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9c2f9bdac64b>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import types\n",
    "import time\n",
    "from utils import TBLogger\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import ops\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "numpy.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(x, hparams):\n",
    "    sizes = [hparams.n_inputs] + [hparams.n_hidden for _ in range(hparams.n_layers)] + [hparams.n_targets]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = tf.Variable(tf.truncated_normal(sizes[i:i+2], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[sizes[i+1]]))\n",
    "        x = tf.matmul(x, w) + b\n",
    "        \n",
    "        shift = tf.reduce_mean(w, axis=1, keepdims=True)\n",
    "        relative = w = tf.tile(shifts, [hparams.n_clients, 1])\n",
    "        \n",
    "        shifts = tf.expand_dims(tf.reduce_mean(weights, axis=0), 0)\n",
    "    relative = weights - tf.tile(shifts, [hparams.n_clients, 1]) + hparams.market_shift * tf.ones([hparams.n_clients, 1 + hparams.n_experts]) \n",
    "    masks = tf.nn.relu(relative)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(hparams):    \n",
    "    inputs = tf.placeholder(\"float\", [None, hparams.n_inputs], 'inputs')\n",
    "    targets = tf.placeholder(\"float\", [None, hparams.n_targets], 'targets')   \n",
    "    \n",
    "    masks = []\n",
    "    x = inputs\n",
    "    sizes = [hparams.n_inputs] + [hparams.n_hidden for _ in range(hparams.n_layers)] + [hparams.n_targets]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        \n",
    "        # Layer weights.\n",
    "        w = tf.Variable(tf.truncated_normal(sizes[i:i+2], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[sizes[i+1]]))\n",
    "        \n",
    "        # Layer flows\n",
    "        f = tf.Variable(tf.truncated_normal(sizes[i:i+2], stddev=0.1))\n",
    "        \n",
    "        # Flow from neuron i to j sums to 1. \n",
    "        f = tf.linalg.normalize(f, axis=0, ord=1)[0]\n",
    "        \n",
    "        # Market shift\n",
    "        s = tf.tile(tf.reduce_mean(f, axis=0, keepdims=True), [sizes[i], 1])\n",
    "        relative = f - s\n",
    "        mask = tf.nn.relu(relative)\n",
    "        masks.append(mask)\n",
    "        \n",
    "        # Apply the mask to the weights.\n",
    "        w = tf.multiply(w, mask)\n",
    "        \n",
    "        # Use the weights.\n",
    "        x = tf.matmul(x, w) + b \n",
    "                \n",
    "    logits = x\n",
    "        \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=targets, logits=logits))\n",
    "    correct = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    full_loss = loss # + (hparams.alpha * norm_sum)\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(hparams.learning_rate).minimize(full_loss)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    for i,m in enumerate(masks):\n",
    "        metrics['sparsity_in_mask_' + str(i)] = tf.nn.zero_fraction(m)\n",
    "        \n",
    "    return train_step, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.3024254\n",
      "accuracy:  0.10546875\n",
      "sparsity_in_mask_0:  0.49952167\n",
      "sparsity_in_mask_1:  0.49972534\n",
      "sparsity_in_mask_2:  0.50078124\n",
      "-\n",
      "loss:  1.9941278\n",
      "accuracy:  0.28125\n",
      "sparsity_in_mask_0:  0.54268974\n",
      "sparsity_in_mask_1:  0.6105499\n",
      "sparsity_in_mask_2:  0.9515625\n",
      "-\n",
      "loss:  1.3186861\n",
      "accuracy:  0.55078125\n",
      "sparsity_in_mask_0:  0.5486488\n",
      "sparsity_in_mask_1:  0.61087036\n",
      "sparsity_in_mask_2:  0.9867188\n",
      "-\n",
      "loss:  1.1376976\n",
      "accuracy:  0.5859375\n",
      "sparsity_in_mask_0:  0.55245036\n",
      "sparsity_in_mask_1:  0.6102295\n",
      "sparsity_in_mask_2:  0.98828125\n",
      "-\n",
      "loss:  1.1617646\n",
      "accuracy:  0.62890625\n",
      "sparsity_in_mask_0:  0.55288386\n",
      "sparsity_in_mask_1:  0.61161804\n",
      "sparsity_in_mask_2:  0.98945314\n",
      "-\n",
      "loss:  0.95963544\n",
      "accuracy:  0.69140625\n",
      "sparsity_in_mask_0:  0.552844\n",
      "sparsity_in_mask_1:  0.61172485\n",
      "sparsity_in_mask_2:  0.9898438\n",
      "-\n",
      "loss:  0.8561187\n",
      "accuracy:  0.75\n",
      "sparsity_in_mask_0:  0.55279416\n",
      "sparsity_in_mask_1:  0.6117401\n",
      "sparsity_in_mask_2:  0.9898438\n",
      "-\n",
      "loss:  0.9932647\n",
      "accuracy:  0.7109375\n",
      "sparsity_in_mask_0:  0.5528041\n",
      "sparsity_in_mask_1:  0.6117401\n",
      "sparsity_in_mask_2:  0.9902344\n",
      "-\n",
      "loss:  0.81710815\n",
      "accuracy:  0.7421875\n",
      "sparsity_in_mask_0:  0.5527144\n",
      "sparsity_in_mask_1:  0.6117401\n",
      "sparsity_in_mask_2:  0.9902344\n",
      "-\n",
      "loss:  0.82837534\n",
      "accuracy:  0.7421875\n",
      "sparsity_in_mask_0:  0.5526945\n",
      "sparsity_in_mask_1:  0.6117401\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.79251426\n",
      "accuracy:  0.76953125\n",
      "sparsity_in_mask_0:  0.5527144\n",
      "sparsity_in_mask_1:  0.613327\n",
      "sparsity_in_mask_2:  0.9902344\n",
      "-\n",
      "loss:  0.70129514\n",
      "accuracy:  0.8046875\n",
      "sparsity_in_mask_0:  0.55448323\n",
      "sparsity_in_mask_1:  0.613327\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.746169\n",
      "accuracy:  0.79296875\n",
      "sparsity_in_mask_0:  0.55456793\n",
      "sparsity_in_mask_1:  0.6133423\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.73115516\n",
      "accuracy:  0.73828125\n",
      "sparsity_in_mask_0:  0.5546277\n",
      "sparsity_in_mask_1:  0.613327\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.72368383\n",
      "accuracy:  0.74609375\n",
      "sparsity_in_mask_0:  0.5545729\n",
      "sparsity_in_mask_1:  0.613327\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.8199539\n",
      "accuracy:  0.74609375\n",
      "sparsity_in_mask_0:  0.5547323\n",
      "sparsity_in_mask_1:  0.61331177\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.6070752\n",
      "accuracy:  0.8203125\n",
      "sparsity_in_mask_0:  0.5559331\n",
      "sparsity_in_mask_1:  0.61331177\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.6532914\n",
      "accuracy:  0.7734375\n",
      "sparsity_in_mask_0:  0.5559481\n",
      "sparsity_in_mask_1:  0.61331177\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.69637537\n",
      "accuracy:  0.7734375\n",
      "sparsity_in_mask_0:  0.55588824\n",
      "sparsity_in_mask_1:  0.61331177\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.6102035\n",
      "accuracy:  0.82421875\n",
      "sparsity_in_mask_0:  0.5561175\n",
      "sparsity_in_mask_1:  0.6131439\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.5595639\n",
      "accuracy:  0.8046875\n",
      "sparsity_in_mask_0:  0.5593311\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.61955446\n",
      "accuracy:  0.796875\n",
      "sparsity_in_mask_0:  0.55936104\n",
      "sparsity_in_mask_1:  0.6132202\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.68764126\n",
      "accuracy:  0.80859375\n",
      "sparsity_in_mask_0:  0.5589874\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.513801\n",
      "accuracy:  0.8359375\n",
      "sparsity_in_mask_0:  0.55927634\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.550049\n",
      "accuracy:  0.8359375\n",
      "sparsity_in_mask_0:  0.5592415\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.4888234\n",
      "accuracy:  0.84765625\n",
      "sparsity_in_mask_0:  0.5592614\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.55929494\n",
      "accuracy:  0.83203125\n",
      "sparsity_in_mask_0:  0.5592315\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.57623994\n",
      "accuracy:  0.83984375\n",
      "sparsity_in_mask_0:  0.5592315\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.5779276\n",
      "accuracy:  0.828125\n",
      "sparsity_in_mask_0:  0.5592315\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.4498706\n",
      "accuracy:  0.8828125\n",
      "sparsity_in_mask_0:  0.5592215\n",
      "sparsity_in_mask_1:  0.6132355\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.61919737\n",
      "accuracy:  0.84765625\n",
      "sparsity_in_mask_0:  0.5592265\n",
      "sparsity_in_mask_1:  0.61325073\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.5503824\n",
      "accuracy:  0.8046875\n",
      "sparsity_in_mask_0:  0.5592215\n",
      "sparsity_in_mask_1:  0.61325073\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.55679786\n",
      "accuracy:  0.8203125\n",
      "sparsity_in_mask_0:  0.5591966\n",
      "sparsity_in_mask_1:  0.61325073\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.6120985\n",
      "accuracy:  0.79296875\n",
      "sparsity_in_mask_0:  0.55919164\n",
      "sparsity_in_mask_1:  0.61325073\n",
      "sparsity_in_mask_2:  0.9910156\n",
      "-\n",
      "loss:  0.5354937\n",
      "accuracy:  0.87109375\n",
      "sparsity_in_mask_0:  0.5592215\n",
      "sparsity_in_mask_1:  0.6121216\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.49024066\n",
      "accuracy:  0.83984375\n",
      "sparsity_in_mask_0:  0.5592415\n",
      "sparsity_in_mask_1:  0.6103668\n",
      "sparsity_in_mask_2:  0.9886719\n",
      "-\n",
      "loss:  0.43577188\n",
      "accuracy:  0.87890625\n",
      "sparsity_in_mask_0:  0.5592315\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.9902344\n",
      "-\n",
      "loss:  0.5356543\n",
      "accuracy:  0.84375\n",
      "sparsity_in_mask_0:  0.5571488\n",
      "sparsity_in_mask_1:  0.61209106\n",
      "sparsity_in_mask_2:  0.9902344\n",
      "-\n",
      "loss:  0.5451114\n",
      "accuracy:  0.828125\n",
      "sparsity_in_mask_0:  0.5579161\n",
      "sparsity_in_mask_1:  0.6120453\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5812863\n",
      "accuracy:  0.82421875\n",
      "sparsity_in_mask_0:  0.558235\n",
      "sparsity_in_mask_1:  0.6120453\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.49950725\n",
      "accuracy:  0.8359375\n",
      "sparsity_in_mask_0:  0.5583496\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.41275156\n",
      "accuracy:  0.8828125\n",
      "sparsity_in_mask_0:  0.5583695\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5069721\n",
      "accuracy:  0.828125\n",
      "sparsity_in_mask_0:  0.5584094\n",
      "sparsity_in_mask_1:  0.61190796\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5944756\n",
      "accuracy:  0.8125\n",
      "sparsity_in_mask_0:  0.5583695\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5401489\n",
      "accuracy:  0.84375\n",
      "sparsity_in_mask_0:  0.5583496\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.46180153\n",
      "accuracy:  0.84375\n",
      "sparsity_in_mask_0:  0.5583197\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5464387\n",
      "accuracy:  0.84375\n",
      "sparsity_in_mask_0:  0.5583745\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.52637404\n",
      "accuracy:  0.82421875\n",
      "sparsity_in_mask_0:  0.5583795\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5651982\n",
      "accuracy:  0.8359375\n",
      "sparsity_in_mask_0:  0.5583795\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.4679549\n",
      "accuracy:  0.875\n",
      "sparsity_in_mask_0:  0.55836457\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.43084958\n",
      "accuracy:  0.8671875\n",
      "sparsity_in_mask_0:  0.5581104\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5164645\n",
      "accuracy:  0.81640625\n",
      "sparsity_in_mask_0:  0.5587133\n",
      "sparsity_in_mask_1:  0.61172485\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.43805373\n",
      "accuracy:  0.8671875\n",
      "sparsity_in_mask_0:  0.55995893\n",
      "sparsity_in_mask_1:  0.6120758\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n",
      "loss:  0.5748813\n",
      "accuracy:  0.84765625\n",
      "sparsity_in_mask_0:  0.558813\n",
      "sparsity_in_mask_1:  0.6119995\n",
      "sparsity_in_mask_2:  0.990625\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "hparams = types.SimpleNamespace( \n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    n_inputs = 784,\n",
    "    n_targets = 10,\n",
    "    n_layers = 2,\n",
    "    n_hidden = 256,\n",
    "    n_iterations = 1000000,\n",
    "    n_print = 1000,\n",
    "    alpha = 0.00001,\n",
    "    logdir='logs/' + str(int(time.time()))\n",
    ")\n",
    "\n",
    "logger = TBLogger(hparams.logdir)\n",
    "graph = tf.Graph()\n",
    "session = tf.Session(graph=graph)\n",
    "with graph.as_default():\n",
    "    train_step, metrics = model_fn(hparams)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(hparams.n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(hparams.batch_size)\n",
    "    feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
    "    session.run(train_step, feeds)\n",
    "\n",
    "    if i % hparams.n_print == 0:\n",
    "        feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
    "        train_metrics = session.run(metrics, feeds)\n",
    "        for key in train_metrics:\n",
    "            print (str(key) + \":  \" + str(train_metrics[key]))\n",
    "        print ('-')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
