{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "PriceOfAnarchy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew-mcateer/GradientBidding/blob/master/PriceOfAnarchy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQxV2W3x4UP6",
        "colab_type": "text"
      },
      "source": [
        "# Price of Anarchy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCi7MPSK37Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import types\n",
        "import random\n",
        "import numpy\n",
        "from numpy import linalg as LA\n",
        "numpy.set_printoptions(precision=3, suppress=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OUVsSLv37J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alloc(mode, contrib, hparams):\n",
        "    graph = tf.Graph()\n",
        "    session = tf.Session(graph=graph)\n",
        "    \n",
        "    # Build optimization problem.\n",
        "    with graph.as_default():\n",
        "        \n",
        "        # Contribution: W* :  The True (i,j)-utility  \n",
        "        Contribution = tf.constant(contrib, tf.float32)\n",
        "\n",
        "        # Weights: W: Contribution row of W.\n",
        "        weights_list = []\n",
        "        for _ in range(n):\n",
        "            weights_i = tf.Variable(tf.random.uniform((1, hparams.n_nodes), minval=0))\n",
        "            weights_list.append(weights_i)\n",
        "        Weights = tf.concat(weights_list, axis=0)\n",
        "        \n",
        "        # We force weights onto [0,1] using the sigmoid and then normalize.\n",
        "        Weights_sig = tf.sigmoid(Weights)\n",
        "        Weights_norm = tf.linalg.normalize(Weights_sig, ord=1, axis=1)[0]\n",
        "        \n",
        "        # Weights_diag: Is the matrix with the main diagonal of Weights. a.k.a self-contribution.\n",
        "        Weights_diag = tf.matrix_set_diag(tf.zeros((hparams.n_nodes, hparams.n_nodes)), tf.linalg.tensor_diag_part(Weights_norm), k = 0)\n",
        "\n",
        "        # Interranking: Q: The inter-model ranking derived from the weights. We use the infinite series\n",
        "        # absorbing markov chain calculation. \n",
        "        Interranking = tf.linalg.inv(tf.eye(hparams.n_nodes) - Weights_norm + Weights_diag)\n",
        "        \n",
        "        Interranking_mean = tf.reshape(tf.tile(tf.reduce_mean(Interranking, axis=0), [hparams.n_nodes]), [hparams.n_nodes, hparams.n_nodes])\n",
        "        Divergence = tf.nn.sigmoid_cross_entropy_with_logits(labels=Interranking_mean, logits=Interranking)\n",
        "        \n",
        "        # Emission: E :The quantity of additional stake attributed to the nodes.\n",
        "        Emission = tf.linalg.tensor_diag_part(Interranking * Weights_diag)\n",
        "\n",
        "        # Market_Contribution: The allocation function shifted contribution scores given the bids.\n",
        "        Market_Shift = tf.reduce_mean(Weights_norm, axis=1)\n",
        "        Masked_Contribution = tf.multiply(Contribution, tf.nn.relu(Weights_norm - Market_Shift))\n",
        "        \n",
        "        # Utility: U: The utility gained from the loss function given the masked contributions.\n",
        "        Utility = tf.reduce_sum(Masked_Contribution, axis=1)\n",
        "\n",
        "        # Payoff: P: Utility + Emission\n",
        "        Payoff = Utility + Emission - hparams.divergence_gamma *tf.reduce_sum(Divergence, axis=1)\n",
        "        \n",
        "        ### Bellow Optimization.\n",
        "\n",
        "        # Bidders move in the direction of the gradient of the Payoff.\n",
        "        optimizer = tf.train.AdamOptimizer(hparams.learning_rate)\n",
        "        \n",
        "        # Mode == Competitive: All nodes optimize only their local payoff. \n",
        "        train_steps = []\n",
        "        if mode == 'competitive':\n",
        "            for i in range(hparams.n_nodes):\n",
        "                payoff_i = tf.slice(Payoff, [i], [1])\n",
        "                weights_i = weights_list[i]\n",
        "                grads_and_vars_i = optimizer.compute_gradients(loss=-payoff_i, var_list=[weights_i])\n",
        "                train_steps.append(optimizer.apply_gradients(grads_and_vars_i))\n",
        "\n",
        "        # Mode == Coordinated: Coordinated nodes optimize the aggregated payoff\n",
        "        elif mode == 'coordinated':\n",
        "            grads_and_vars = optimizer.compute_gradients(loss=-tf.reduce_mean(Payoff), var_list=weights_list)\n",
        "            train_steps.append(optimizer.apply_gradients(grads_and_vars))\n",
        "\n",
        "        # Init the graph.\n",
        "        session.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Converge...\n",
        "        for step in range(hparams.n_steps):\n",
        "            \n",
        "            # Randomly choose participant to optimize\n",
        "            if mode == 'competitive':\n",
        "                step = random.choice(train_steps)\n",
        "                \n",
        "            # Optimize all participants.\n",
        "            elif mode == 'coordinated':\n",
        "                step = train_steps[0]\n",
        "                \n",
        "            # Run graph.\n",
        "            output = session.run(fetches = \n",
        "                                      {   \n",
        "                                        'step': step,       \n",
        "                                        'Payoff': Payoff,   \n",
        "                                        'Utility': Utility, \n",
        "                                        'Emission': Emission,\n",
        "                                        'Divergence': Divergence,\n",
        "                                        'Weights': Weights_norm,  \n",
        "                                        'Mask': Masked_Contribution,\n",
        "                                        'Interranking': Interranking,\n",
        "                                      })      \n",
        "        # Return metrics.\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qZfLgG37J8",
        "colab_type": "code",
        "outputId": "4598caa2-452e-4bad-c5bf-eb40a4c25a97",
        "colab": {}
      },
      "source": [
        "hparams = types.SimpleNamespace( \n",
        "    trials = 1,\n",
        "    n_steps = 1,\n",
        "    learning_rate = 0.05,\n",
        "    n_nodes = 10,\n",
        "    contrib_factor = 1,\n",
        "    divergence_gamma=0.01\n",
        ")\n",
        "\n",
        "\n",
        "for _ in range(hparams.trials):\n",
        "    \n",
        "    # Build \"True\" contribution matrix.\n",
        "    contribution = numpy.random.randn(hparams.n_nodes, hparams.n_nodes)\n",
        "    contribution = (contribution - numpy.min(contribution))/numpy.ptp(contribution)\n",
        "    contribution = contribution/contribution.sum(axis=1, keepdims=1) * hparams.contrib_factor\n",
        "    \n",
        "    print ('Contribution: W*')\n",
        "    print (contribution)\n",
        "    print ('')\n",
        "    \n",
        "    # Run coordinated weight convergence.\n",
        "    coord_output = alloc('coordinated', contribution, hparams)\n",
        "    \n",
        "    # Run competitive weight convergence.\n",
        "    comp_output = alloc('competitive', contribution, hparams)\n",
        "    \n",
        "    print ('Coordinated Mask: M')\n",
        "    print (coord_output['Mask'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Mask: M')\n",
        "    print (comp_output['Mask'])\n",
        "    print ('')\n",
        "\n",
        "    print ('Coordinated Weights: W')\n",
        "    print (coord_output['Weights'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Weights: W')\n",
        "    print (comp_output['Weights'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Coordinated Interranking: Q')\n",
        "    print (coord_output['Interranking'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitve Interranking: Q')\n",
        "    print (comp_output['Interranking'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Coordinated Divergence: D')\n",
        "    print (coord_output['Divergence'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Divergence: D')\n",
        "    print (comp_output['Divergence'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Coordinated Emission: E')\n",
        "    print (coord_output['Emission'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Emission: E')\n",
        "    print (comp_output['Emission'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Coordinated Utility: U')\n",
        "    print (coord_output['Utility'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Utility: U')\n",
        "    print (comp_output['Utility'])\n",
        "    print ('')\n",
        "    \n",
        "    print ('Coordinated Payoff: P')\n",
        "    print (coord_output['Payoff'])\n",
        "    print ('Avg:' + str(sum(coord_output['Payoff'])/hparams.n_nodes))\n",
        "    print ('')\n",
        "    \n",
        "    print ('Competitive Payoff: P')\n",
        "    print (comp_output['Payoff'])\n",
        "    print ('Avg:' + str(sum(comp_output['Payoff'])/hparams.n_nodes))\n",
        "    print ('')\n",
        "\n",
        "    poa = sum(comp_output['Payoff']) / sum(coord_output['Payoff'])\n",
        "    print ('Price of Anarchy: ' + str(poa))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contribution: W*\n",
            "[[0.107 0.106 0.045 0.103 0.116 0.083 0.086 0.067 0.12  0.168]\n",
            " [0.079 0.084 0.145 0.037 0.12  0.097 0.079 0.171 0.062 0.127]\n",
            " [0.078 0.117 0.132 0.114 0.086 0.083 0.15  0.137 0.08  0.023]\n",
            " [0.011 0.131 0.065 0.129 0.081 0.107 0.122 0.052 0.19  0.114]\n",
            " [0.103 0.036 0.1   0.146 0.092 0.138 0.077 0.102 0.074 0.131]\n",
            " [0.175 0.149 0.078 0.087 0.106 0.108 0.145 0.038 0.046 0.067]\n",
            " [0.072 0.154 0.082 0.101 0.1   0.078 0.107 0.101 0.099 0.106]\n",
            " [0.132 0.06  0.11  0.161 0.051 0.052 0.031 0.131 0.157 0.115]\n",
            " [0.088 0.068 0.135 0.087 0.119 0.11  0.152 0.059 0.058 0.125]\n",
            " [0.097 0.126 0.114 0.065 0.112 0.114 0.134 0.    0.112 0.127]]\n",
            "\n",
            "Coordinated Mask: M\n",
            "[[0.    0.    0.001 0.    0.    0.    0.    0.001 0.001 0.001]\n",
            " [0.    0.001 0.002 0.    0.    0.    0.    0.    0.001 0.   ]\n",
            " [0.001 0.    0.    0.001 0.    0.001 0.    0.002 0.    0.   ]\n",
            " [0.    0.    0.001 0.    0.    0.    0.    0.001 0.002 0.   ]\n",
            " [0.001 0.    0.001 0.    0.001 0.    0.    0.    0.001 0.   ]\n",
            " [0.001 0.    0.    0.    0.    0.001 0.    0.    0.    0.001]\n",
            " [0.    0.    0.    0.    0.001 0.    0.001 0.    0.001 0.   ]\n",
            " [0.    0.    0.    0.002 0.001 0.    0.    0.001 0.    0.   ]\n",
            " [0.    0.    0.002 0.    0.002 0.    0.001 0.    0.    0.002]\n",
            " [0.    0.    0.    0.    0.002 0.    0.    0.    0.    0.002]]\n",
            "\n",
            "Competitive Mask: M\n",
            "[[0.    0.    0.    0.    0.    0.    0.    0.001 0.    0.003]\n",
            " [0.001 0.001 0.001 0.    0.    0.    0.    0.    0.    0.001]\n",
            " [0.    0.001 0.    0.001 0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.001 0.    0.    0.    0.002 0.001 0.    0.    0.001]\n",
            " [0.    0.    0.001 0.001 0.    0.001 0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.001 0.    0.001 0.    0.    0.   ]\n",
            " [0.001 0.    0.    0.    0.    0.    0.002 0.    0.002 0.001]\n",
            " [0.    0.    0.001 0.003 0.    0.    0.    0.    0.    0.002]\n",
            " [0.001 0.    0.001 0.    0.001 0.001 0.    0.001 0.    0.   ]\n",
            " [0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.001]]\n",
            "\n",
            "Coordinated Weights: W\n",
            "[[0.095 0.095 0.113 0.085 0.092 0.098 0.091 0.113 0.112 0.106]\n",
            " [0.082 0.107 0.11  0.103 0.095 0.102 0.097 0.095 0.11  0.099]\n",
            " [0.119 0.084 0.1   0.105 0.085 0.111 0.091 0.114 0.09  0.1  ]\n",
            " [0.102 0.099 0.111 0.085 0.096 0.099 0.099 0.111 0.112 0.086]\n",
            " [0.105 0.088 0.11  0.086 0.11  0.101 0.103 0.089 0.112 0.096]\n",
            " [0.107 0.085 0.106 0.099 0.102 0.112 0.091 0.085 0.099 0.114]\n",
            " [0.098 0.085 0.103 0.086 0.114 0.103 0.105 0.098 0.113 0.095]\n",
            " [0.098 0.1   0.094 0.111 0.112 0.108 0.1   0.109 0.081 0.088]\n",
            " [0.094 0.093 0.113 0.103 0.115 0.099 0.11  0.079 0.08  0.114]\n",
            " [0.094 0.092 0.086 0.088 0.114 0.102 0.091 0.116 0.104 0.112]]\n",
            "\n",
            "Competitive Weights: W\n",
            "[[0.087 0.095 0.107 0.087 0.097 0.1   0.091 0.116 0.103 0.118]\n",
            " [0.113 0.117 0.106 0.097 0.089 0.091 0.103 0.093 0.086 0.105]\n",
            " [0.103 0.107 0.1   0.105 0.082 0.102 0.097 0.096 0.103 0.105]\n",
            " [0.096 0.11  0.089 0.092 0.091 0.115 0.107 0.095 0.096 0.11 ]\n",
            " [0.097 0.112 0.111 0.107 0.102 0.107 0.104 0.084 0.081 0.097]\n",
            " [0.09  0.102 0.099 0.094 0.108 0.101 0.108 0.11  0.089 0.101]\n",
            " [0.111 0.096 0.09  0.082 0.102 0.08  0.117 0.096 0.116 0.111]\n",
            " [0.093 0.087 0.108 0.122 0.105 0.094 0.088 0.093 0.091 0.12 ]\n",
            " [0.108 0.094 0.11  0.082 0.111 0.105 0.083 0.115 0.103 0.09 ]\n",
            " [0.083 0.1   0.106 0.106 0.103 0.088 0.093 0.109 0.104 0.11 ]]\n",
            "\n",
            "Coordinated Interranking: Q\n",
            "[[1.811 0.832 0.949 0.861 0.915 0.92  0.871 0.913 0.936 0.905]\n",
            " [0.877 1.736 0.937 0.867 0.908 0.913 0.866 0.887 0.926 0.89 ]\n",
            " [0.914 0.819 1.843 0.873 0.905 0.926 0.866 0.91  0.914 0.896]\n",
            " [0.911 0.843 0.955 1.79  0.926 0.929 0.885 0.919 0.945 0.897]\n",
            " [0.894 0.814 0.934 0.849 1.818 0.909 0.868 0.88  0.924 0.884]\n",
            " [0.894 0.811 0.928 0.859 0.909 1.816 0.857 0.876 0.913 0.898]\n",
            " [0.892 0.816 0.932 0.853 0.925 0.915 1.779 0.891 0.929 0.887]\n",
            " [0.889 0.825 0.921 0.871 0.919 0.916 0.866 1.799 0.899 0.878]\n",
            " [0.909 0.841 0.962 0.887 0.946 0.933 0.898 0.897 1.849 0.924]\n",
            " [0.882 0.817 0.912 0.85  0.919 0.908 0.857 0.9   0.916 1.795]]\n",
            "\n",
            "Competitve Interranking: Q\n",
            "[[1.806 0.901 0.931 0.878 0.89  0.888 0.873 0.927 0.882 0.965]\n",
            " [0.885 1.79  0.905 0.863 0.859 0.857 0.86  0.883 0.845 0.929]\n",
            " [0.89  0.901 1.823 0.883 0.867 0.88  0.868 0.9   0.872 0.944]\n",
            " [0.889 0.909 0.91  1.793 0.88  0.896 0.882 0.905 0.872 0.953]\n",
            " [0.883 0.903 0.92  0.882 1.789 0.882 0.874 0.888 0.852 0.935]\n",
            " [0.878 0.895 0.911 0.873 0.887 1.786 0.877 0.91  0.859 0.939]\n",
            " [0.882 0.877 0.891 0.85  0.87  0.848 1.766 0.886 0.869 0.933]\n",
            " [0.887 0.89  0.926 0.903 0.892 0.879 0.867 1.818 0.868 0.962]\n",
            " [0.892 0.888 0.921 0.862 0.889 0.88  0.855 0.913 1.776 0.929]\n",
            " [0.865 0.887 0.91  0.876 0.876 0.86  0.857 0.902 0.864 1.839]]\n",
            "\n",
            "Coordinated Divergence: D\n",
            "[[0.174 0.432 0.302 0.391 0.329 0.328 0.383 0.349 0.317 0.353]\n",
            " [0.359 0.309 0.305 0.389 0.331 0.33  0.385 0.356 0.32  0.357]\n",
            " [0.349 0.434 0.097 0.387 0.332 0.326 0.384 0.35  0.323 0.355]\n",
            " [0.349 0.429 0.299 0.233 0.325 0.325 0.38  0.348 0.314 0.355]\n",
            " [0.354 0.436 0.306 0.394 0.134 0.331 0.384 0.359 0.32  0.358]\n",
            " [0.354 0.436 0.308 0.391 0.33  0.135 0.387 0.359 0.324 0.355]\n",
            " [0.355 0.435 0.307 0.393 0.326 0.329 0.225 0.355 0.319 0.358]\n",
            " [0.356 0.433 0.31  0.388 0.328 0.329 0.385 0.177 0.328 0.36 ]\n",
            " [0.35  0.43  0.297 0.384 0.319 0.324 0.376 0.354 0.118 0.348]\n",
            " [0.357 0.435 0.313 0.393 0.328 0.331 0.387 0.353 0.323 0.18 ]]\n",
            "\n",
            "Competitive Divergence: D\n",
            "[[0.196 0.355 0.328 0.377 0.371 0.375 0.386 0.34  0.385 0.291]\n",
            " [0.367 0.183 0.335 0.381 0.379 0.383 0.389 0.352 0.395 0.302]\n",
            " [0.366 0.355 0.141 0.376 0.377 0.377 0.387 0.347 0.388 0.298]\n",
            " [0.366 0.353 0.334 0.215 0.374 0.373 0.383 0.346 0.388 0.295]\n",
            " [0.368 0.354 0.331 0.376 0.209 0.377 0.386 0.351 0.393 0.301]\n",
            " [0.369 0.357 0.333 0.379 0.372 0.216 0.385 0.344 0.391 0.299]\n",
            " [0.368 0.362 0.339 0.385 0.376 0.386 0.232 0.351 0.389 0.301]\n",
            " [0.367 0.358 0.329 0.371 0.371 0.377 0.387 0.163 0.389 0.292]\n",
            " [0.365 0.359 0.331 0.381 0.371 0.377 0.39  0.344 0.235 0.302]\n",
            " [0.372 0.359 0.334 0.378 0.375 0.383 0.39  0.347 0.39  0.087]]\n",
            "\n",
            "Coordinated Emission: E\n",
            "[0.172 0.185 0.184 0.153 0.201 0.203 0.187 0.196 0.147 0.201]\n",
            "\n",
            "Competitive Emission: E\n",
            "[0.157 0.209 0.181 0.165 0.182 0.18  0.206 0.168 0.182 0.202]\n",
            "\n",
            "Coordinated Utility: U\n",
            "[0.004 0.003 0.005 0.004 0.004 0.004 0.004 0.004 0.007 0.004]\n",
            "\n",
            "Competitive Utility: U\n",
            "[0.005 0.004 0.002 0.005 0.004 0.003 0.005 0.007 0.005 0.003]\n",
            "\n",
            "Coordinated Payoff: P\n",
            "[0.142 0.154 0.156 0.123 0.171 0.173 0.157 0.166 0.121 0.171]\n",
            "Avg:0.15344132259488105\n",
            "\n",
            "Competitive Payoff: P\n",
            "[0.128 0.178 0.15  0.136 0.151 0.148 0.177 0.141 0.153 0.171]\n",
            "Avg:0.1532753363251686\n",
            "\n",
            "Price of Anarchy: 0.9989182427073398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NwyDgdh37KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw9brH2j37KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}