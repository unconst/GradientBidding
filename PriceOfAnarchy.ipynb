{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unconst/GradientBidding/blob/master/PriceOfAnarchy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQxV2W3x4UP6"
   },
   "source": [
    "# Price of Anarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCi7MPSK37Jz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import types\n",
    "import random\n",
    "import numpy\n",
    "from numpy import linalg as LA\n",
    "numpy.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OUVsSLv37J4"
   },
   "outputs": [],
   "source": [
    "def alloc(mode, contrib, hparams):\n",
    "    graph = tf.Graph()\n",
    "    session = tf.Session(graph=graph)\n",
    "    \n",
    "    # Build optimization problem.\n",
    "    with graph.as_default():\n",
    "        \n",
    "        # Contribution: W* :  The True (i,j)-utility  \n",
    "        Contribution = tf.constant(contrib, tf.float32)\n",
    "\n",
    "        # Weights: W: Contribution row of W.\n",
    "        weights_list = []\n",
    "        for _ in range(n):\n",
    "            weights_i = tf.Variable(tf.random.uniform((1, hparams.n_nodes), minval=0))\n",
    "            weights_list.append(weights_i)\n",
    "        Weights = tf.concat(weights_list, axis=0)\n",
    "        \n",
    "        # We force weights onto [0,1] using the sigmoid and then normalize.\n",
    "        Weights_sig = tf.sigmoid(Weights)\n",
    "        Weights_norm = tf.linalg.normalize(Weights_sig, ord=1, axis=1)[0]\n",
    "        \n",
    "        # Weights_diag: Is the matrix with the main diagonal of Weights. a.k.a self-contribution.\n",
    "        Weights_diag = tf.matrix_set_diag(tf.zeros((hparams.n_nodes, hparams.n_nodes)), tf.linalg.tensor_diag_part(Weights_norm), k = 0)\n",
    "\n",
    "        # Interranking: Q: The inter-model ranking derived from the weights. We use the infinite series\n",
    "        # absorbing markov chain calculation. \n",
    "        Interranking = tf.linalg.inv(tf.eye(hparams.n_nodes) - Weights_norm + Weights_diag)\n",
    "        Interranking = tf.linalg.normalize(Interranking, ord=1, axis=1)[0]\n",
    "\n",
    "        # Divergence score.\n",
    "        Interranking_mean = tf.reshape(tf.tile(tf.reduce_mean(Interranking, axis=0), [hparams.n_nodes]), [hparams.n_nodes, hparams.n_nodes])\n",
    "        cross_entropy = -tf.reduce_sum(tf.multiply(Interranking_mean, tf.log(Interranking)), axis=1)\n",
    "        Divergence = hparams.gamma * tf.reshape(cross_entropy, [10])\n",
    "        \n",
    "        # Emission: E :The quantity of additional stake attributed to the nodes.\n",
    "        Emission = tf.linalg.tensor_diag_part(Interranking * Weights_diag)\n",
    "\n",
    "        # Market_Contribution: The allocation function shifted contribution scores given the bids.\n",
    "        Market_Shift = tf.reduce_mean(Weights_norm, axis=1)\n",
    "        Masked_Contribution = tf.multiply(Contribution, tf.nn.relu(Weights_norm - Market_Shift))\n",
    "        \n",
    "        # Utility: U: The utility gained from the loss function given the masked contributions.\n",
    "        Utility = tf.reduce_sum(Masked_Contribution, axis=1)\n",
    "\n",
    "        # Payoff: P: Utility + Emission\n",
    "        Payoff = Utility + Emission - Divergence\n",
    "        \n",
    "        ### Bellow Optimization.\n",
    "\n",
    "        # Bidders move in the direction of the gradient of the Payoff.\n",
    "        optimizer = tf.train.AdamOptimizer(hparams.learning_rate)\n",
    "        \n",
    "        # Mode == Competitive: All nodes optimize only their local payoff. \n",
    "        train_steps = []\n",
    "        if mode == 'competitive':\n",
    "            for i in range(hparams.n_nodes):\n",
    "                payoff_i = tf.slice(Payoff, [i], [1])\n",
    "                weights_i = weights_list[i]\n",
    "                grads_and_vars_i = optimizer.compute_gradients(loss=-payoff_i, var_list=[weights_i])\n",
    "                train_steps.append(optimizer.apply_gradients(grads_and_vars_i))\n",
    "\n",
    "        # Mode == Coordinated: Coordinated nodes optimize the aggregated payoff\n",
    "        elif mode == 'coordinated':\n",
    "            grads_and_vars = optimizer.compute_gradients(loss=-tf.reduce_mean(Payoff), var_list=weights_list)\n",
    "            train_steps.append(optimizer.apply_gradients(grads_and_vars))\n",
    "\n",
    "        # Init the graph.\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Converge...\n",
    "        for step in range(hparams.n_steps):\n",
    "            \n",
    "            # Randomly choose participant to optimize\n",
    "            if mode == 'competitive':\n",
    "                step = random.choice(train_steps)\n",
    "                \n",
    "            # Optimize all participants.\n",
    "            elif mode == 'coordinated':\n",
    "                step = train_steps[0]\n",
    "                \n",
    "            # Run graph.\n",
    "            output = session.run(fetches = \n",
    "                                      {   \n",
    "                                        'step': step,       \n",
    "                                        'Payoff': Payoff,   \n",
    "                                        'Utility': Utility, \n",
    "                                        'Emission': Emission,\n",
    "                                        'Divergence': Divergence,\n",
    "                                        'Weights': Weights_norm,  \n",
    "                                        'Mask': Masked_Contribution,\n",
    "                                        'Interranking': Interranking,\n",
    "                                      })      \n",
    "        # Return metrics.\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6qZfLgG37J8",
    "outputId": "4598caa2-452e-4bad-c5bf-eb40a4c25a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution: W*\n",
      "[[0.099 0.118 0.094 0.138 0.11  0.068 0.176 0.087 0.029 0.082]\n",
      " [0.14  0.1   0.147 0.1   0.091 0.077 0.091 0.047 0.135 0.074]\n",
      " [0.102 0.114 0.106 0.11  0.064 0.111 0.131 0.066 0.071 0.124]\n",
      " [0.113 0.091 0.071 0.132 0.088 0.065 0.125 0.144 0.056 0.116]\n",
      " [0.073 0.06  0.134 0.127 0.043 0.08  0.161 0.127 0.091 0.105]\n",
      " [0.15  0.099 0.1   0.086 0.082 0.072 0.094 0.107 0.069 0.142]\n",
      " [0.13  0.083 0.152 0.129 0.07  0.095 0.09  0.044 0.084 0.121]\n",
      " [0.121 0.123 0.081 0.064 0.119 0.131 0.05  0.082 0.126 0.103]\n",
      " [0.08  0.105 0.091 0.145 0.111 0.153 0.071 0.065 0.045 0.133]\n",
      " [0.122 0.086 0.098 0.076 0.156 0.135 0.    0.079 0.107 0.141]]\n",
      "\n",
      "Coordinated Mask: M\n",
      "[[0.    0.    0.    0.    0.    0.    0.159 0.    0.    0.   ]\n",
      " [0.125 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.117 0.    0.    0.   ]\n",
      " [0.045 0.    0.    0.    0.    0.    0.05  0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.145 0.    0.    0.   ]\n",
      " [0.065 0.    0.    0.    0.    0.    0.    0.    0.    0.051]\n",
      " [0.117 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.108 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.13  0.    0.    0.    0.    0.    0.   ]\n",
      " [0.105 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n",
      "\n",
      "Competitive Mask: M\n",
      "[[0.068 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.067 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.073 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.089 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.028 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.049 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.062 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.056 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.032 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.098]]\n",
      "\n",
      "Coordinated Weights: W\n",
      "[[0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
      " [0.998 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.997 0.    0.    0.   ]\n",
      " [0.5   0.    0.    0.    0.    0.    0.499 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.998 0.    0.    0.   ]\n",
      " [0.536 0.001 0.    0.    0.    0.001 0.    0.    0.    0.461]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.997 0.    0.    0.    0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.    0.    0.001 0.996 0.    0.001 0.    0.    0.001 0.001]\n",
      " [0.959 0.    0.    0.036 0.    0.    0.001 0.    0.001 0.001]]\n",
      "\n",
      "Competitive Weights: W\n",
      "[[0.789 0.023 0.026 0.023 0.023 0.022 0.025 0.024 0.023 0.023]\n",
      " [0.023 0.771 0.028 0.023 0.025 0.025 0.026 0.025 0.029 0.024]\n",
      " [0.024 0.023 0.788 0.023 0.023 0.023 0.023 0.024 0.025 0.024]\n",
      " [0.028 0.024 0.025 0.776 0.024 0.023 0.026 0.023 0.025 0.025]\n",
      " [0.028 0.027 0.024 0.027 0.764 0.027 0.025 0.024 0.027 0.025]\n",
      " [0.026 0.025 0.024 0.024 0.023 0.784 0.025 0.021 0.026 0.023]\n",
      " [0.026 0.022 0.026 0.022 0.024 0.023 0.787 0.024 0.023 0.022]\n",
      " [0.025 0.024 0.023 0.024 0.025 0.022 0.022 0.785 0.024 0.025]\n",
      " [0.024 0.026 0.021 0.02  0.023 0.012 0.024 0.015 0.811 0.023]\n",
      " [0.023 0.022 0.022 0.023 0.022 0.021 0.023 0.023 0.024 0.797]]\n",
      "\n",
      "Coordinated Interranking: Q\n",
      "[[0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]\n",
      " [0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ]]\n",
      "\n",
      "Competitve Interranking: Q\n",
      "[[0.794 0.022 0.025 0.023 0.023 0.021 0.024 0.023 0.023 0.022]\n",
      " [0.023 0.78  0.027 0.023 0.024 0.024 0.025 0.024 0.027 0.024]\n",
      " [0.024 0.023 0.792 0.023 0.023 0.023 0.023 0.023 0.024 0.023]\n",
      " [0.027 0.024 0.024 0.783 0.024 0.022 0.025 0.023 0.024 0.024]\n",
      " [0.027 0.025 0.024 0.026 0.775 0.025 0.025 0.023 0.026 0.024]\n",
      " [0.025 0.024 0.023 0.023 0.022 0.789 0.024 0.021 0.025 0.023]\n",
      " [0.025 0.022 0.025 0.022 0.023 0.022 0.792 0.023 0.023 0.022]\n",
      " [0.025 0.024 0.023 0.023 0.024 0.022 0.022 0.79  0.024 0.024]\n",
      " [0.024 0.025 0.022 0.02  0.023 0.014 0.024 0.017 0.811 0.022]\n",
      " [0.023 0.022 0.022 0.022 0.022 0.021 0.023 0.022 0.024 0.799]]\n",
      "\n",
      "Coordinated Divergence: D\n",
      "[0.347 0.347 0.347 0.347 0.347 0.347 0.347 0.347 0.347 0.347]\n",
      "\n",
      "Competitive Divergence: D\n",
      "[1.708 1.685 1.707 1.692 1.675 1.704 1.706 1.705 1.749 1.721]\n",
      "\n",
      "Coordinated Emission: E\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Competitive Emission: E\n",
      "[0.626 0.601 0.624 0.608 0.592 0.619 0.623 0.62  0.658 0.637]\n",
      "\n",
      "Coordinated Utility: U\n",
      "[0.159 0.125 0.117 0.095 0.145 0.117 0.117 0.108 0.13  0.105]\n",
      "\n",
      "Competitive Utility: U\n",
      "[0.068 0.067 0.073 0.089 0.028 0.049 0.062 0.056 0.032 0.098]\n",
      "\n",
      "Coordinated Payoff: P\n",
      "[-0.189 -0.222 -0.23  -0.252 -0.202 -0.231 -0.231 -0.239 -0.217 -0.243]\n",
      "Avg:-0.22557374686002732\n",
      "\n",
      "Competitive Payoff: P\n",
      "[-1.013 -1.016 -1.009 -0.995 -1.055 -1.037 -1.021 -1.029 -1.059 -0.986]\n",
      "Avg:-1.0219862043857575\n",
      "\n",
      "Price of Anarchy: 4.530607921408154\n"
     ]
    }
   ],
   "source": [
    "hparams = types.SimpleNamespace( \n",
    "    trials = 1,\n",
    "    n_steps = 1000,\n",
    "    learning_rate = 0.05,\n",
    "    n_nodes = 10,\n",
    "    contrib_factor = 1,\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "\n",
    "for _ in range(hparams.trials):\n",
    "    \n",
    "    # Build \"True\" contribution matrix.\n",
    "    contribution = numpy.random.randn(hparams.n_nodes, hparams.n_nodes)\n",
    "    contribution = (contribution - numpy.min(contribution))/numpy.ptp(contribution)\n",
    "    contribution = contribution/contribution.sum(axis=1, keepdims=1) * hparams.contrib_factor\n",
    "    \n",
    "    print ('Contribution: W*')\n",
    "    print (contribution)\n",
    "    print ('')\n",
    "    \n",
    "    # Run coordinated weight convergence.\n",
    "    coord_output = alloc('coordinated', contribution, hparams)\n",
    "    \n",
    "    # Run competitive weight convergence.\n",
    "    comp_output = alloc('competitive', contribution, hparams)\n",
    "    \n",
    "    print ('Coordinated Mask: M')\n",
    "    print (coord_output['Mask'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Mask: M')\n",
    "    print (comp_output['Mask'])\n",
    "    print ('')\n",
    "\n",
    "    print ('Coordinated Weights: W')\n",
    "    print (coord_output['Weights'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Weights: W')\n",
    "    print (comp_output['Weights'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Coordinated Interranking: Q')\n",
    "    print (coord_output['Interranking'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitve Interranking: Q')\n",
    "    print (comp_output['Interranking'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Coordinated Divergence: D')\n",
    "    print (coord_output['Divergence'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Divergence: D')\n",
    "    print (comp_output['Divergence'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Coordinated Emission: E')\n",
    "    print (coord_output['Emission'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Emission: E')\n",
    "    print (comp_output['Emission'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Coordinated Utility: U')\n",
    "    print (coord_output['Utility'])\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Utility: U')\n",
    "    print (comp_output['Utility'])\n",
    "    print ('')\n",
    "        \n",
    "    print ('Coordinated Payoff: P')\n",
    "    print (coord_output['Payoff'])\n",
    "    print ('Avg:' + str(sum(coord_output['Payoff'])/hparams.n_nodes))\n",
    "    print ('')\n",
    "    \n",
    "    print ('Competitive Payoff: P')\n",
    "    print (comp_output['Payoff'])\n",
    "    print ('Avg:' + str(sum(comp_output['Payoff'])/hparams.n_nodes))\n",
    "    print ('')\n",
    "\n",
    "    poa = sum(comp_output['Payoff']) / sum(coord_output['Payoff'])\n",
    "    print ('Price of Anarchy: ' + str(poa))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NwyDgdh37KB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bw9brH2j37KE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "PriceOfAnarchy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
