{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Singlebidder.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unconst/GradientBidding/blob/master/Singlebidder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJdD-9Q436h9",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Bidding: Single Bidder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82u7Rg_PICst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "e9839e81-ca77-491c-e6ea-1202a02069d6"
      },
      "source": [
        "!wget https://github.com/unconst/GradientBidding/raw/master/utils_moe.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-23 02:04:21--  https://github.com/unconst/GradientBidding/raw/master/utils_moe.py\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/unconst/GradientBidding/master/utils_moe.py [following]\n",
            "--2020-01-23 02:04:22--  https://raw.githubusercontent.com/unconst/GradientBidding/master/utils_moe.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37803 (37K) [text/plain]\n",
            "Saving to: ‘utils_moe.py’\n",
            "\n",
            "\rutils_moe.py          0%[                    ]       0  --.-KB/s               \rutils_moe.py        100%[===================>]  36.92K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-01-23 02:04:22 (4.35 MB/s) - ‘utils_moe.py’ saved [37803/37803]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_LRA8-Y36h-",
        "colab_type": "code",
        "outputId": "776501c4-897d-43ca-9c66-c6ffe3865d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import types\n",
        "from utils_moe import noisy_top_k_gating\n",
        "from utils_moe import SparseDispatcher\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-a86030244733>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN1esEyI36iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FFNN with biases.\n",
        "def expert(i, x, hparams):\n",
        "    with tf.compat.v1.variable_scope(\"expert\"):\n",
        "        sizes = [hparams.n_inputs] + [hparams.e_hidden for _ in range(hparams.e_layers)] + [hparams.n_embedding]\n",
        "        for i in range(len(sizes) - 1):\n",
        "            w = tf.Variable(tf.truncated_normal([sizes[i], sizes[i+1]], stddev=0.1))\n",
        "            b = tf.Variable(tf.constant(0.1, shape=[sizes[i+1]]))\n",
        "            x = tf.matmul(x, w) + b\n",
        "    return x\n",
        "\n",
        "# Cross entropy loss + accuracy.\n",
        "def target_loss(embedding, targets, hparams):\n",
        "    with tf.compat.v1.variable_scope(\"target_loss\"):\n",
        "        w = tf.Variable(tf.truncated_normal([hparams.n_embedding, hparams.n_targets], stddev=0.1))\n",
        "        b = tf.Variable(tf.constant(0.1, shape=[hparams.n_targets])),\n",
        "        logits = tf.add(tf.matmul(embedding, w), b)\n",
        "        target_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=targets, logits=logits))\n",
        "        correct = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "        return target_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSQRqQyw36iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Incentive function inputs weights, outputs revenue.\n",
        "# This the most basic, just takes the inloop weight as your score\n",
        "def incentive_fn(weights, hparams):\n",
        "    weights = tf.linalg.normalize(weights)\n",
        "    return tf.slice(weights, [0], [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-qM7rk36iJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(hparams):    \n",
        "    x_inputs = tf.placeholder(\"float\", [None, hparams.n_inputs], 'inputs')\n",
        "    y_targets = tf.placeholder(\"float\", [None, hparams.n_targets], 'targets')    \n",
        "    \n",
        "    # Sparsely gated mixture of experts with choice k. Produces an importance score \n",
        "    # for each x_input then chooses the topk. These children recieve the outgoing query.\n",
        "    # expert_inputs is a list of tensors, inputs for each expert.\n",
        "    gates, load = noisy_top_k_gating(x_inputs, hparams.n_experts, train = True, k = hparams.k)\n",
        "    dispatcher = SparseDispatcher(hparams.n_experts, gates)\n",
        "    expert_inputs = dispatcher.dispatch(x_inputs)\n",
        "\n",
        "    # Basic importance scores can attained from the gating network by summing over the importance \n",
        "    # of each example. We choose a 'self-importance' score here which counts as the in-loop to our\n",
        "    # incentive function. The network should try to maximize this value.\n",
        "    importance = tf.linalg.normalize(tf.reduce_sum(gates, 0))[0]\n",
        "    self_weight = tf.Variable(tf.constant([1.0]))\n",
        "    weights = tf.linalg.normalize(tf.concat([self_weight, importance], axis=0))[0]\n",
        "    revenue = tf.slice(weights, [0], [1])\n",
        "    \n",
        "    # Dispatch the inputs to the experts. We mask the responses with a faux-bidding system,\n",
        "    # here, we set a mask w.r.t the bids with a hparams.market_shift shifted relu. Bids that\n",
        "    # drop bellow the market shift should zero out.\n",
        "    expert_outputs = []\n",
        "    expert_masks = []\n",
        "    for i in range(hparams.n_experts):\n",
        "        expert_output = expert(i, expert_inputs[i], hparams)\n",
        "        \n",
        "        # Apply mask to the output.\n",
        "        expert_mask = tf.nn.relu(tf.slice(weights, [i], [1]) - hparams.market_shift)\n",
        "        masked_output = expert_mask * expert_output\n",
        "        \n",
        "        expert_masks.append(expert_mask)\n",
        "        expert_outputs.append(masked_output)\n",
        "    expert_masks = tf.concat(expert_masks, axis=0)\n",
        "\n",
        "    \n",
        "    # Combine the expert_inputs.\n",
        "    embedding = dispatcher.combine(expert_outputs)\n",
        "        \n",
        "    # Loss and accuracy stuff.\n",
        "    loss, accuracy = target_loss(embedding, y_targets, hparams)\n",
        "    \n",
        "    # Run the step: optimize for loss and revenue. \n",
        "    train_step = tf.train.AdamOptimizer(hparams.learning_rate).minimize(loss - revenue)\n",
        "    \n",
        "    metrics = {\n",
        "        'loss': loss,\n",
        "        'revenue': revenue,\n",
        "        'accuracy': accuracy,\n",
        "        'importance': importance,\n",
        "        'weights': weights,\n",
        "        'masks': expert_masks,\n",
        "    }\n",
        "    return train_step, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfXd1gMv36iL",
        "colab_type": "code",
        "outputId": "da2b8a77-e020-4fc7-f7f2-c85e8557759f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hparams = types.SimpleNamespace( \n",
        "    n_inputs = 784,\n",
        "    n_targets = 10,\n",
        "    k = 3,\n",
        "    n_experts = 3,\n",
        "    e_layers = 2,\n",
        "    e_hidden = 256,\n",
        "    n_embedding = 256,\n",
        "    batch_size=256,\n",
        "    learning_rate=1e-3,\n",
        "    n_iterations = 10000,\n",
        "    n_print = 100,\n",
        "    market_shift = 0.2,\n",
        ")\n",
        "\n",
        "graph = tf.Graph()\n",
        "session = tf.Session(graph=graph)\n",
        "with graph.as_default():\n",
        "    train_step, metrics = model_fn(hparams)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(hparams.n_iterations):\n",
        "    batch_x, batch_y = mnist.train.next_batch(hparams.batch_size)\n",
        "    feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
        "    session.run(train_step, feeds)\n",
        "\n",
        "    if i % hparams.n_print == 0:\n",
        "        feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
        "        train_metrics = session.run(metrics, feeds)\n",
        "        print(\"Iteration: \" + str(i))\n",
        "        for key in train_metrics:\n",
        "            print (str(key) + \":  \" + str(train_metrics[key]))\n",
        "        print ('-')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "loss:  1.8183292\n",
            "revenue:  [0.7074601]\n",
            "accuracy:  0.5234375\n",
            "importance:  [0.5131693  0.63815343 0.57394904]\n",
            "weights:  [0.7074601  0.3626841  0.45101705 0.4056404 ]\n",
            "masks:  [0.5074601  0.1626841  0.25101703]\n",
            "-\n",
            "Iteration: 100\n",
            "loss:  0.23909731\n",
            "revenue:  [0.7403392]\n",
            "accuracy:  0.9296875\n",
            "importance:  [0.59748584 0.78650296 0.15628135]\n",
            "weights:  [0.7403392  0.40165    0.52871364 0.10505757]\n",
            "masks:  [0.54033923 0.20165001 0.32871366]\n",
            "-\n",
            "Iteration: 200\n",
            "loss:  0.1776205\n",
            "revenue:  [0.7665271]\n",
            "accuracy:  0.9375\n",
            "importance:  [0.57273656 0.7867943  0.2300598 ]\n",
            "weights:  [0.7665271  0.36781827 0.5052887  0.14774716]\n",
            "masks:  [0.5665271  0.16781826 0.30528873]\n",
            "-\n",
            "Iteration: 300\n",
            "loss:  0.17145687\n",
            "revenue:  [0.78780156]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.54288346 0.7867947  0.29365212]\n",
            "weights:  [0.78780156 0.3343777  0.48460975 0.18086888]\n",
            "masks:  [0.5878016  0.1343777  0.28460974]\n",
            "-\n",
            "Iteration: 400\n",
            "loss:  0.1533003\n",
            "revenue:  [0.80568117]\n",
            "accuracy:  0.94921875\n",
            "importance:  [0.62325436 0.72954404 0.28163704]\n",
            "weights:  [0.80568117 0.36918437 0.43214503 0.16682756]\n",
            "masks:  [0.6056812  0.16918437 0.23214503]\n",
            "-\n",
            "Iteration: 500\n",
            "loss:  0.22025666\n",
            "revenue:  [0.82039297]\n",
            "accuracy:  0.93359375\n",
            "importance:  [0.58697104 0.7446905  0.31764945]\n",
            "weights:  [0.82039297 0.33563012 0.4258141  0.181632  ]\n",
            "masks:  [0.620393   0.13563012 0.22581409]\n",
            "-\n",
            "Iteration: 600\n",
            "loss:  0.14746204\n",
            "revenue:  [0.8331583]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.5944624 0.7314572 0.3340431]\n",
            "weights:  [0.8331583  0.32875827 0.40452114 0.18473738]\n",
            "masks:  [0.6331583  0.12875827 0.20452113]\n",
            "-\n",
            "Iteration: 700\n",
            "loss:  0.1257916\n",
            "revenue:  [0.8442532]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.59585404 0.7104956  0.37437135]\n",
            "weights:  [0.8442532  0.31934476 0.38078627 0.2006423 ]\n",
            "masks:  [0.6442532  0.11934476 0.18078627]\n",
            "-\n",
            "Iteration: 800\n",
            "loss:  0.14204288\n",
            "revenue:  [0.85359824]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.5828716 0.7176454 0.3811112]\n",
            "weights:  [0.85359824 0.30363637 0.37384436 0.19853295]\n",
            "masks:  [0.65359825 0.10363637 0.17384435]\n",
            "-\n",
            "Iteration: 900\n",
            "loss:  0.24069084\n",
            "revenue:  [0.8621233]\n",
            "accuracy:  0.93359375\n",
            "importance:  [0.55795664 0.7480909  0.3592276 ]\n",
            "weights:  [0.8621233  0.28271583 0.37905657 0.1820201 ]\n",
            "masks:  [0.6621233  0.08271582 0.17905657]\n",
            "-\n",
            "Iteration: 1000\n",
            "loss:  0.107104905\n",
            "revenue:  [0.8695418]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.64805037 0.659947   0.3801325 ]\n",
            "weights:  [0.8695418  0.3200457  0.32592094 0.18773197]\n",
            "masks:  [0.66954184 0.12004571 0.12592094]\n",
            "-\n",
            "Iteration: 1100\n",
            "loss:  0.1518027\n",
            "revenue:  [0.876083]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.63169587 0.65875673 0.40865627]\n",
            "weights:  [0.876083   0.3045787  0.31762636 0.19703785]\n",
            "masks:  [0.676083   0.10457869 0.11762635]\n",
            "-\n",
            "Iteration: 1200\n",
            "loss:  0.1295293\n",
            "revenue:  [0.8819244]\n",
            "accuracy:  0.94921875\n",
            "importance:  [0.59660596 0.699527   0.39334887]\n",
            "weights:  [0.8819244  0.2812346  0.32975066 0.18542106]\n",
            "masks:  [0.6819244  0.08123459 0.12975065]\n",
            "-\n",
            "Iteration: 1300\n",
            "loss:  0.16210084\n",
            "revenue:  [0.88709676]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.64168674 0.67539996 0.3634184 ]\n",
            "weights:  [0.88709676 0.29619196 0.31175342 0.16774791]\n",
            "masks:  [0.6870968  0.09619196 0.11175342]\n",
            "-\n",
            "Iteration: 1400\n",
            "loss:  0.15150769\n",
            "revenue:  [0.89202315]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6377684  0.64120185 0.42674524]\n",
            "weights:  [0.89202315 0.2882648  0.2898167  0.19288449]\n",
            "masks:  [0.69202316 0.08826481 0.0898167 ]\n",
            "-\n",
            "Iteration: 1500\n",
            "loss:  0.098406374\n",
            "revenue:  [0.89640456]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.61234546 0.7083378  0.35112756]\n",
            "weights:  [0.89640456 0.27141392 0.31396124 0.15563259]\n",
            "masks:  [0.6964046  0.07141392 0.11396123]\n",
            "-\n",
            "Iteration: 1600\n",
            "loss:  0.09850934\n",
            "revenue:  [0.899833]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.61023796 0.6985322  0.37371418]\n",
            "weights:  [0.899833   0.2662068  0.3047238  0.16302699]\n",
            "masks:  [0.69983304 0.0662068  0.1047238 ]\n",
            "-\n",
            "Iteration: 1700\n",
            "loss:  0.10433684\n",
            "revenue:  [0.9036834]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.63007116 0.6763901  0.38145354]\n",
            "weights:  [0.9036834  0.2697973  0.28963113 0.1633389 ]\n",
            "masks:  [0.70368344 0.06979729 0.08963113]\n",
            "-\n",
            "Iteration: 1800\n",
            "loss:  0.10322964\n",
            "revenue:  [0.9067288]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6366233 0.7150796 0.2887417]\n",
            "weights:  [0.9067288  0.26847312 0.30155927 0.12176649]\n",
            "masks:  [0.7067288  0.06847312 0.10155927]\n",
            "-\n",
            "Iteration: 1900\n",
            "loss:  0.086126216\n",
            "revenue:  [0.90969074]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.6279906  0.67808115 0.38188192]\n",
            "weights:  [0.90969074 0.26079598 0.28159788 0.15859038]\n",
            "masks:  [0.70969075 0.06079598 0.08159788]\n",
            "-\n",
            "Iteration: 2000\n",
            "loss:  0.054268137\n",
            "revenue:  [0.9121668]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.65039825 0.6747426  0.34886187]\n",
            "weights:  [0.9121668  0.26654568 0.27652246 0.1429703 ]\n",
            "masks:  [0.7121668  0.06654568 0.07652245]\n",
            "-\n",
            "Iteration: 2100\n",
            "loss:  0.092361756\n",
            "revenue:  [0.9142909]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.6941162  0.6128749  0.37760702]\n",
            "weights:  [0.9142909  0.28115737 0.24824995 0.15295278]\n",
            "masks:  [0.7142909  0.08115737 0.04824995]\n",
            "-\n",
            "Iteration: 2200\n",
            "loss:  0.12873842\n",
            "revenue:  [0.9163645]\n",
            "accuracy:  0.94921875\n",
            "importance:  [0.6164347  0.70757043 0.34547412]\n",
            "weights:  [0.9163645  0.24678656 0.2832723  0.13830885]\n",
            "masks:  [0.7163645  0.04678656 0.08327229]\n",
            "-\n",
            "Iteration: 2300\n",
            "loss:  0.15605985\n",
            "revenue:  [0.91819316]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.6586065  0.67985094 0.3225525 ]\n",
            "weights:  [0.91819316 0.2608957  0.2693113  0.12777366]\n",
            "masks:  [0.7181932  0.0608957  0.06931131]\n",
            "-\n",
            "Iteration: 2400\n",
            "loss:  0.15571384\n",
            "revenue:  [0.920401]\n",
            "accuracy:  0.9453125\n",
            "importance:  [0.6215466  0.7360964  0.26803368]\n",
            "weights:  [0.920401   0.24300969 0.28779587 0.10479468]\n",
            "masks:  [0.720401   0.04300968 0.08779587]\n",
            "-\n",
            "Iteration: 2500\n",
            "loss:  0.12675956\n",
            "revenue:  [0.9220162]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.72822565 0.6247478  0.28174043]\n",
            "weights:  [0.9220162  0.28193346 0.24187188 0.10907615]\n",
            "masks:  [0.7220162  0.08193345 0.04187188]\n",
            "-\n",
            "Iteration: 2600\n",
            "loss:  0.21420929\n",
            "revenue:  [0.91997594]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.9093518  0.3661426  0.19753227]\n",
            "weights:  [0.91997594 0.35644314 0.14351873 0.0774277 ]\n",
            "masks:  [0.71997595 0.15644313 0.        ]\n",
            "-\n",
            "Iteration: 2700\n",
            "loss:  0.15808475\n",
            "revenue:  [0.9224248]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.6560547  0.7192242  0.22871117]\n",
            "weights:  [0.9224248  0.253353   0.2777476  0.08832292]\n",
            "masks:  [0.7224248 0.053353  0.0777476]\n",
            "-\n",
            "Iteration: 2800\n",
            "loss:  0.11305657\n",
            "revenue:  [0.9235596]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.68643045 0.6662495  0.2914187 ]\n",
            "weights:  [0.9235596  0.26321512 0.25547662 0.11174592]\n",
            "masks:  [0.7235596  0.06321512 0.05547662]\n",
            "-\n",
            "Iteration: 2900\n",
            "loss:  0.09067509\n",
            "revenue:  [0.92445886]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.64154303 0.7253998  0.24943468]\n",
            "weights:  [0.92445886 0.2446087  0.27658176 0.09510491]\n",
            "masks:  [0.7244589  0.0446087  0.07658176]\n",
            "-\n",
            "Iteration: 3000\n",
            "loss:  0.17629446\n",
            "revenue:  [0.92535645]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.6722117  0.68686044 0.27632257]\n",
            "weights:  [0.92535645 0.2548342  0.2603875  0.10475337]\n",
            "masks:  [0.72535646 0.0548342  0.06038751]\n",
            "-\n",
            "Iteration: 3100\n",
            "loss:  0.08704133\n",
            "revenue:  [0.92644155]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.68432254 0.6761835  0.2729077 ]\n",
            "weights:  [0.92644155 0.2576054  0.25454158 0.10273299]\n",
            "masks:  [0.72644156 0.0576054  0.05454157]\n",
            "-\n",
            "Iteration: 3200\n",
            "loss:  0.12055514\n",
            "revenue:  [0.92779464]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.6915183  0.67830205 0.24841233]\n",
            "weights:  [0.92779464 0.25799936 0.2530685  0.09268045]\n",
            "masks:  [0.72779465 0.05799936 0.0530685 ]\n",
            "-\n",
            "Iteration: 3300\n",
            "loss:  0.06727476\n",
            "revenue:  [0.92803955]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.62127185 0.7469968  0.23667906]\n",
            "weights:  [0.92803955 0.23141237 0.27824262 0.08815861]\n",
            "masks:  [0.72803956 0.03141236 0.07824261]\n",
            "-\n",
            "Iteration: 3400\n",
            "loss:  0.099651456\n",
            "revenue:  [0.92916596]\n",
            "accuracy:  0.94921875\n",
            "importance:  [0.72432476 0.642563   0.24993275]\n",
            "weights:  [0.92916596 0.26775604 0.23753174 0.09239088]\n",
            "masks:  [0.729166   0.06775604 0.03753173]\n",
            "-\n",
            "Iteration: 3500\n",
            "loss:  0.069357514\n",
            "revenue:  [0.92961365]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.7498542  0.6173476  0.23790902]\n",
            "weights:  [0.92961365 0.27634802 0.22751461 0.08767796]\n",
            "masks:  [0.72961366 0.07634802 0.02751461]\n",
            "-\n",
            "Iteration: 3600\n",
            "loss:  0.1154484\n",
            "revenue:  [0.9290895]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.70389336 0.67554504 0.2194839 ]\n",
            "weights:  [0.9290895  0.26033852 0.24985375 0.08117723]\n",
            "masks:  [0.7290895  0.06033851 0.04985374]\n",
            "-\n",
            "Iteration: 3700\n",
            "loss:  0.06281759\n",
            "revenue:  [0.9302388]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.6840872  0.68580985 0.24837373]\n",
            "weights:  [0.9302388  0.25102907 0.2516612  0.09114192]\n",
            "masks:  [0.7302388  0.05102907 0.05166121]\n",
            "-\n",
            "Iteration: 3800\n",
            "loss:  0.15311122\n",
            "revenue:  [0.9301965]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6795651  0.70167065 0.21412547]\n",
            "weights:  [0.9301965  0.2494425  0.25755662 0.07859731]\n",
            "masks:  [0.73019654 0.0494425  0.05755661]\n",
            "-\n",
            "Iteration: 3900\n",
            "loss:  0.09597414\n",
            "revenue:  [0.9313969]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.6440521  0.7113956  0.28127068]\n",
            "weights:  [0.9313969  0.2344383  0.2589517  0.10238399]\n",
            "masks:  [0.7313969  0.0344383  0.05895169]\n",
            "-\n",
            "Iteration: 4000\n",
            "loss:  0.11018015\n",
            "revenue:  [0.93170273]\n",
            "accuracy:  0.9609375\n",
            "importance:  [0.7406023  0.63178766 0.22880682]\n",
            "weights:  [0.93170273 0.26900268 0.22947887 0.08310755]\n",
            "masks:  [0.73170274 0.06900267 0.02947886]\n",
            "-\n",
            "Iteration: 4100\n",
            "loss:  0.05551163\n",
            "revenue:  [0.9320359]\n",
            "accuracy:  0.9921875\n",
            "importance:  [0.6558148  0.7103584  0.25553435]\n",
            "weights:  [0.9320359  0.23764502 0.25740975 0.09259696]\n",
            "masks:  [0.73203593 0.03764501 0.05740975]\n",
            "-\n",
            "Iteration: 4200\n",
            "loss:  0.10733685\n",
            "revenue:  [0.9327158]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.6577361  0.69728434 0.28491697]\n",
            "weights:  [0.9327158  0.23718774 0.25144932 0.10274456]\n",
            "masks:  [0.7327158  0.03718774 0.05144931]\n",
            "-\n",
            "Iteration: 4300\n",
            "loss:  0.039434828\n",
            "revenue:  [0.9330124]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.6883777  0.6775311  0.25901282]\n",
            "weights:  [0.9330124  0.24770872 0.24380565 0.09320426]\n",
            "masks:  [0.73301244 0.04770872 0.04380564]\n",
            "-\n",
            "Iteration: 4400\n",
            "loss:  0.122004196\n",
            "revenue:  [0.9329761]\n",
            "accuracy:  0.953125\n",
            "importance:  [0.62459743 0.7374486  0.25699747]\n",
            "weights:  [0.9329761  0.22481655 0.265436   0.09250323]\n",
            "masks:  [0.73297614 0.02481654 0.06543599]\n",
            "-\n",
            "Iteration: 4500\n",
            "loss:  0.099246144\n",
            "revenue:  [0.93326706]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.61821944 0.7429268  0.25664097]\n",
            "weights:  [0.93326706 0.222054   0.26684678 0.09218112]\n",
            "masks:  [0.73326707 0.022054   0.06684677]\n",
            "-\n",
            "Iteration: 4600\n",
            "loss:  0.08818539\n",
            "revenue:  [0.93135375]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.72367316 0.64136624 0.2548458 ]\n",
            "weights:  [0.93135375 0.26350087 0.23353162 0.0927934 ]\n",
            "masks:  [0.73135376 0.06350087 0.03353162]\n",
            "-\n",
            "Iteration: 4700\n",
            "loss:  0.10147634\n",
            "revenue:  [0.9305971]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.7651156  0.63156825 0.12537773]\n",
            "weights:  [0.9305971  0.2800668  0.23118244 0.0458939 ]\n",
            "masks:  [0.73059714 0.08006679 0.03118244]\n",
            "-\n",
            "Iteration: 4800\n",
            "loss:  0.052960612\n",
            "revenue:  [0.9305901]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.717648   0.66988486 0.19035639]\n",
            "weights:  [0.9305901  0.26270425 0.24521995 0.0696824 ]\n",
            "masks:  [0.7305901  0.06270425 0.04521994]\n",
            "-\n",
            "Iteration: 4900\n",
            "loss:  0.088020906\n",
            "revenue:  [0.9311216]\n",
            "accuracy:  0.9609375\n",
            "importance:  [0.69777066 0.6844947  0.211147  ]\n",
            "weights:  [0.9311216  0.25448328 0.2496414  0.07700722]\n",
            "masks:  [0.7311216  0.05448328 0.0496414 ]\n",
            "-\n",
            "Iteration: 5000\n",
            "loss:  0.1280992\n",
            "revenue:  [0.93200624]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.70274615 0.6720756  0.23337129]\n",
            "weights:  [0.93200624 0.25470486 0.24358857 0.0845836 ]\n",
            "masks:  [0.73200625 0.05470486 0.04358856]\n",
            "-\n",
            "Iteration: 5100\n",
            "loss:  0.08506131\n",
            "revenue:  [0.93260306]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.62668127 0.7386748  0.24825415]\n",
            "weights:  [0.93260306 0.22617148 0.26659036 0.0895958 ]\n",
            "masks:  [0.7326031  0.02617148 0.06659035]\n",
            "-\n",
            "Iteration: 5200\n",
            "loss:  0.077942275\n",
            "revenue:  [0.93236107]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.6856926  0.68963754 0.2328642 ]\n",
            "weights:  [0.93236107 0.24789733 0.24932353 0.08418702]\n",
            "masks:  [0.7323611  0.04789732 0.04932353]\n",
            "-\n",
            "Iteration: 5300\n",
            "loss:  0.055624932\n",
            "revenue:  [0.93301255]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.70265627 0.6686705  0.24321589]\n",
            "weights:  [0.93301255 0.25284657 0.24061698 0.08751975]\n",
            "masks:  [0.73301256 0.05284657 0.04061697]\n",
            "-\n",
            "Iteration: 5400\n",
            "loss:  0.098190054\n",
            "revenue:  [0.9337324]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.7129521  0.66642475 0.21812262]\n",
            "weights:  [0.9337324  0.25521663 0.23856115 0.07808171]\n",
            "masks:  [0.7337324  0.05521663 0.03856115]\n",
            "-\n",
            "Iteration: 5500\n",
            "loss:  0.03390248\n",
            "revenue:  [0.93396693]\n",
            "accuracy:  0.99609375\n",
            "importance:  [0.70050097 0.64741635 0.3002505 ]\n",
            "weights:  [0.93396693 0.2503307  0.2313604  0.10729738]\n",
            "masks:  [0.73396695 0.05033068 0.0313604 ]\n",
            "-\n",
            "Iteration: 5600\n",
            "loss:  0.040024854\n",
            "revenue:  [0.9344851]\n",
            "accuracy:  0.9921875\n",
            "importance:  [0.66173065 0.69757414 0.274778  ]\n",
            "weights:  [0.9344851  0.23557772 0.24833809 0.09782164]\n",
            "masks:  [0.7344851  0.03557771 0.04833809]\n",
            "-\n",
            "Iteration: 5700\n",
            "loss:  0.08115689\n",
            "revenue:  [0.934713]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6741268  0.70094573 0.23286925]\n",
            "weights:  [0.934713   0.23958686 0.24911839 0.08276249]\n",
            "masks:  [0.734713   0.03958686 0.04911838]\n",
            "-\n",
            "Iteration: 5800\n",
            "loss:  0.093040206\n",
            "revenue:  [0.93485487]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.66396016 0.72383094 0.18768522]\n",
            "weights:  [0.93485487 0.23572588 0.25698182 0.06663391]\n",
            "masks:  [0.7348549  0.03572588 0.05698182]\n",
            "-\n",
            "Iteration: 5900\n",
            "loss:  0.11871605\n",
            "revenue:  [0.93259454]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.76134485 0.6232789  0.1785426 ]\n",
            "weights:  [0.93259454 0.27478892 0.22495736 0.06444061]\n",
            "masks:  [0.73259455 0.07478891 0.02495736]\n",
            "-\n",
            "Iteration: 6000\n",
            "loss:  0.11530311\n",
            "revenue:  [0.9336245]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.66627103 0.70811456 0.2337875 ]\n",
            "weights:  [0.9336245  0.23869365 0.25368422 0.0837551 ]\n",
            "masks:  [0.7336245  0.03869365 0.05368422]\n",
            "-\n",
            "Iteration: 6100\n",
            "loss:  0.08949419\n",
            "revenue:  [0.93426627]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.69366056 0.6729213  0.256928  ]\n",
            "weights:  [0.93426627 0.24734277 0.23994765 0.09161438]\n",
            "masks:  [0.7342663  0.04734276 0.03994764]\n",
            "-\n",
            "Iteration: 6200\n",
            "loss:  0.1086874\n",
            "revenue:  [0.9345968]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.67371875 0.6823152  0.28381166]\n",
            "weights:  [0.9345968  0.23964797 0.2427058  0.10095443]\n",
            "masks:  [0.7345968  0.03964797 0.0427058 ]\n",
            "-\n",
            "Iteration: 6300\n",
            "loss:  0.080002844\n",
            "revenue:  [0.93492335]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.7165626  0.66106087 0.22256798]\n",
            "weights:  [0.93492335 0.25427204 0.23457725 0.07897818]\n",
            "masks:  [0.73492336 0.05427204 0.03457725]\n",
            "-\n",
            "Iteration: 6400\n",
            "loss:  0.12928833\n",
            "revenue:  [0.9347691]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.7364745  0.6327419  0.23925513]\n",
            "weights:  [0.9347691  0.261637   0.22478537 0.08499683]\n",
            "masks:  [0.7347691  0.061637   0.02478537]\n",
            "-\n",
            "Iteration: 6500\n",
            "loss:  0.08664179\n",
            "revenue:  [0.9351091]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.623915   0.7399721  0.25133884]\n",
            "weights:  [0.9351091  0.22109051 0.2622165  0.08906443]\n",
            "masks:  [0.7351091  0.02109051 0.06221651]\n",
            "-\n",
            "Iteration: 6600\n",
            "loss:  0.059739333\n",
            "revenue:  [0.935716]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.720453   0.6398461  0.26747784]\n",
            "weights:  [0.935716   0.2541429  0.22570845 0.09435396]\n",
            "masks:  [0.735716   0.05414291 0.02570845]\n",
            "-\n",
            "Iteration: 6700\n",
            "loss:  0.082482316\n",
            "revenue:  [0.93556666]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.67122465 0.7278332  0.14041436]\n",
            "weights:  [0.93556666 0.2370431  0.25703442 0.04958735]\n",
            "masks:  [0.7355667  0.03704309 0.05703442]\n",
            "-\n",
            "Iteration: 6800\n",
            "loss:  0.111742295\n",
            "revenue:  [0.9351357]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.7281149  0.6450002  0.23199876]\n",
            "weights:  [0.9351357  0.2579637  0.228517   0.08219479]\n",
            "masks:  [0.73513573 0.05796368 0.02851699]\n",
            "-\n",
            "Iteration: 6900\n",
            "loss:  0.065529324\n",
            "revenue:  [0.9357188]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.6943273  0.6895172  0.20609617]\n",
            "weights:  [0.9357188  0.24492176 0.24322502 0.07269978]\n",
            "masks:  [0.7357188  0.04492176 0.04322502]\n",
            "-\n",
            "Iteration: 7000\n",
            "loss:  0.04968849\n",
            "revenue:  [0.936065]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.72278214 0.6632772  0.19403397]\n",
            "weights:  [0.936065   0.2542943  0.23335886 0.0682664 ]\n",
            "masks:  [0.73606503 0.0542943  0.03335886]\n",
            "-\n",
            "Iteration: 7100\n",
            "loss:  0.047693744\n",
            "revenue:  [0.9359855]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.6527081  0.72941804 0.20474775]\n",
            "weights:  [0.9359855  0.22977835 0.2567832  0.07207908]\n",
            "masks:  [0.7359855  0.02977835 0.05678318]\n",
            "-\n",
            "Iteration: 7200\n",
            "loss:  0.053347535\n",
            "revenue:  [0.9357458]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.6472721  0.72381955 0.23900677]\n",
            "weights:  [0.9357458  0.22827692 0.2552733  0.08429179]\n",
            "masks:  [0.7357458  0.02827692 0.05527331]\n",
            "-\n",
            "Iteration: 7300\n",
            "loss:  0.084487356\n",
            "revenue:  [0.936083]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.6950873  0.6725626  0.25399455]\n",
            "weights:  [0.936083   0.24451734 0.2365936  0.08935003]\n",
            "masks:  [0.73608303 0.04451734 0.0365936 ]\n",
            "-\n",
            "Iteration: 7400\n",
            "loss:  0.060384285\n",
            "revenue:  [0.9338017]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.7261475 0.6676585 0.1641402]\n",
            "weights:  [0.9338017  0.2598091  0.23888227 0.0587279 ]\n",
            "masks:  [0.7338017  0.0598091  0.03888227]\n",
            "-\n",
            "Iteration: 7500\n",
            "loss:  0.08077099\n",
            "revenue:  [0.9345042]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.70253104 0.67795676 0.21638994]\n",
            "weights:  [0.9345042  0.2500674  0.24132015 0.07702446]\n",
            "masks:  [0.7345042  0.05006741 0.04132015]\n",
            "-\n",
            "Iteration: 7600\n",
            "loss:  0.123181134\n",
            "revenue:  [0.9348227]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6937219  0.6955872  0.18683775]\n",
            "weights:  [0.9348227  0.246351   0.2470134  0.06634887]\n",
            "masks:  [0.7348227 0.046351  0.0470134]\n",
            "-\n",
            "Iteration: 7700\n",
            "loss:  0.04599072\n",
            "revenue:  [0.93540925]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.6786789  0.70714235 0.19835478]\n",
            "weights:  [0.93540925 0.23995829 0.25002202 0.07013166]\n",
            "masks:  [0.73540926 0.03995828 0.05002202]\n",
            "-\n",
            "Iteration: 7800\n",
            "loss:  0.065029636\n",
            "revenue:  [0.9356393]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.69866943 0.6785603  0.22675304]\n",
            "weights:  [0.9356393  0.24660061 0.23950295 0.08003418]\n",
            "masks:  [0.73563933 0.04660061 0.03950295]\n",
            "-\n",
            "Iteration: 7900\n",
            "loss:  0.11281232\n",
            "revenue:  [0.9360053]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.6183783  0.75691205 0.2114058 ]\n",
            "weights:  [0.9360053  0.21766055 0.2664225  0.0744119 ]\n",
            "masks:  [0.7360053  0.01766054 0.06642251]\n",
            "-\n",
            "Iteration: 8000\n",
            "loss:  0.16147989\n",
            "revenue:  [0.9351998]\n",
            "accuracy:  0.95703125\n",
            "importance:  [0.8645206  0.4667772  0.18634152]\n",
            "weights:  [0.9351998  0.30614465 0.16529547 0.06598739]\n",
            "masks:  [0.7351998  0.10614465 0.        ]\n",
            "-\n",
            "Iteration: 8100\n",
            "loss:  0.08239488\n",
            "revenue:  [0.9358922]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.7175388  0.6748999  0.17218678]\n",
            "weights:  [0.9358922  0.2527791  0.23775798 0.06065904]\n",
            "masks:  [0.73589224 0.05277909 0.03775798]\n",
            "-\n",
            "Iteration: 8200\n",
            "loss:  0.043955278\n",
            "revenue:  [0.93612546]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.65875864 0.7144314  0.23584923]\n",
            "weights:  [0.93612546 0.23166318 0.25124142 0.08294021]\n",
            "masks:  [0.73612547 0.03166318 0.05124141]\n",
            "-\n",
            "Iteration: 8300\n",
            "loss:  0.08208104\n",
            "revenue:  [0.93639]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.70975685 0.66650605 0.22806764]\n",
            "weights:  [0.93639    0.24909738 0.23391801 0.08004297]\n",
            "masks:  [0.73639    0.04909737 0.03391801]\n",
            "-\n",
            "Iteration: 8400\n",
            "loss:  0.07048741\n",
            "revenue:  [0.9362392]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.74602246 0.63882333 0.18802977]\n",
            "weights:  [0.9362392  0.262125   0.22445913 0.06606678]\n",
            "masks:  [0.7362392  0.06212498 0.02445912]\n",
            "-\n",
            "Iteration: 8500\n",
            "loss:  0.12578726\n",
            "revenue:  [0.93601525]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.7015517  0.68953633 0.17990224]\n",
            "weights:  [0.93601525 0.24691786 0.24268894 0.06331833]\n",
            "masks:  [0.73601526 0.04691786 0.04268894]\n",
            "-\n",
            "Iteration: 8600\n",
            "loss:  0.030701766\n",
            "revenue:  [0.936092]\n",
            "accuracy:  0.9921875\n",
            "importance:  [0.7369629  0.6605021  0.14360598]\n",
            "weights:  [0.936092   0.25923058 0.23233508 0.05051416]\n",
            "masks:  [0.73609203 0.05923058 0.03233507]\n",
            "-\n",
            "Iteration: 8700\n",
            "loss:  0.10809294\n",
            "revenue:  [0.93604904]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.6143487  0.78573275 0.07210822]\n",
            "weights:  [0.93604904 0.21617061 0.27647543 0.02537269]\n",
            "masks:  [0.73604906 0.01617061 0.07647543]\n",
            "-\n",
            "Iteration: 8800\n",
            "loss:  0.04585864\n",
            "revenue:  [0.9362375]\n",
            "accuracy:  0.9921875\n",
            "importance:  [0.7184358  0.66714984 0.19687852]\n",
            "weights:  [0.9362375  0.25243527 0.23441504 0.06917679]\n",
            "masks:  [0.7362375  0.05243526 0.03441504]\n",
            "-\n",
            "Iteration: 8900\n",
            "loss:  0.097019605\n",
            "revenue:  [0.9363674]\n",
            "accuracy:  0.96875\n",
            "importance:  [0.690504   0.69247925 0.20898966]\n",
            "weights:  [0.9363674  0.24238187 0.24307522 0.0733599 ]\n",
            "masks:  [0.7363674  0.04238187 0.04307522]\n",
            "-\n",
            "Iteration: 9000\n",
            "loss:  0.08388499\n",
            "revenue:  [0.93623644]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.66849023 0.71230495 0.21387495]\n",
            "weights:  [0.93623644 0.23488784 0.25028303 0.07514938]\n",
            "masks:  [0.73623645 0.03488784 0.05028303]\n",
            "-\n",
            "Iteration: 9100\n",
            "loss:  0.045919\n",
            "revenue:  [0.9358549]\n",
            "accuracy:  0.9765625\n",
            "importance:  [0.7026825  0.67793995 0.21595062]\n",
            "weights:  [0.9358549  0.24761514 0.23889622 0.07609788]\n",
            "masks:  [0.7358549  0.04761514 0.03889622]\n",
            "-\n",
            "Iteration: 9200\n",
            "loss:  0.07884984\n",
            "revenue:  [0.9365016]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.7284879  0.65856516 0.18867262]\n",
            "weights:  [0.9365016  0.25545403 0.2309347  0.06616058]\n",
            "masks:  [0.73650163 0.05545403 0.03093469]\n",
            "-\n",
            "Iteration: 9300\n",
            "loss:  0.10894056\n",
            "revenue:  [0.9365338]\n",
            "accuracy:  0.96484375\n",
            "importance:  [0.724725   0.65892786 0.20146398]\n",
            "weights:  [0.9365338  0.25407213 0.23100515 0.0706287 ]\n",
            "masks:  [0.7365338  0.05407213 0.03100514]\n",
            "-\n",
            "Iteration: 9400\n",
            "loss:  0.07366191\n",
            "revenue:  [0.93703777]\n",
            "accuracy:  0.97265625\n",
            "importance:  [0.71198004 0.671337   0.20589069]\n",
            "weights:  [0.93703777 0.24864355 0.23444986 0.07190285]\n",
            "masks:  [0.7370378  0.04864354 0.03444986]\n",
            "-\n",
            "Iteration: 9500\n",
            "loss:  0.05084149\n",
            "revenue:  [0.9373348]\n",
            "accuracy:  0.984375\n",
            "importance:  [0.6237923  0.76113397 0.17764656]\n",
            "weights:  [0.9373348  0.21734796 0.26520193 0.0618974 ]\n",
            "masks:  [0.7373348  0.01734796 0.06520192]\n",
            "-\n",
            "Iteration: 9600\n",
            "loss:  0.074316286\n",
            "revenue:  [0.9363767]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.6700686  0.72472125 0.1605836 ]\n",
            "weights:  [0.9363767  0.23519185 0.25437474 0.05636431]\n",
            "masks:  [0.7363767  0.03519185 0.05437474]\n",
            "-\n",
            "Iteration: 9700\n",
            "loss:  0.035532646\n",
            "revenue:  [0.9369599]\n",
            "accuracy:  0.98828125\n",
            "importance:  [0.69062835 0.6932782  0.20590746]\n",
            "weights:  [0.9369599  0.2413311  0.24225704 0.07195169]\n",
            "masks:  [0.73695993 0.0413311  0.04225704]\n",
            "-\n",
            "Iteration: 9800\n",
            "loss:  0.034259908\n",
            "revenue:  [0.9375766]\n",
            "accuracy:  0.99609375\n",
            "importance:  [0.6913506 0.6876961 0.2216042]\n",
            "weights:  [0.9375766  0.24043709 0.23916614 0.07706925]\n",
            "masks:  [0.7375766  0.04043709 0.03916614]\n",
            "-\n",
            "Iteration: 9900\n",
            "loss:  0.04777526\n",
            "revenue:  [0.9380743]\n",
            "accuracy:  0.98046875\n",
            "importance:  [0.6757267  0.7041415  0.21812417]\n",
            "weights:  [0.9380743  0.23409487 0.24393871 0.07556568]\n",
            "masks:  [0.7380743  0.03409487 0.04393871]\n",
            "-\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}