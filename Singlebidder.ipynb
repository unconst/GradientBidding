{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Bidding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-15038030d943>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import types\n",
    "from utils import noisy_top_k_gating\n",
    "from utils import SparseDispatcher\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FFNN with biases.\n",
    "def expert(i, x, hparams):\n",
    "    with tf.compat.v1.variable_scope(\"expert\"):\n",
    "        sizes = [hparams.n_inputs] + [hparams.e_hidden for _ in range(hparams.e_layers)] + [hparams.n_embedding]\n",
    "        for i in range(len(sizes) - 1):\n",
    "            w = tf.Variable(tf.truncated_normal([sizes[i], sizes[i+1]], stddev=0.1))\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[sizes[i+1]]))\n",
    "            x = tf.matmul(x, w) + b\n",
    "    return x\n",
    "\n",
    "# Cross entropy loss + accuracy.\n",
    "def target_loss(embedding, targets, hparams):\n",
    "    with tf.compat.v1.variable_scope(\"target_loss\"):\n",
    "        w = tf.Variable(tf.truncated_normal([hparams.n_embedding, hparams.n_targets], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[hparams.n_targets])),\n",
    "        logits = tf.add(tf.matmul(embedding, w), b)\n",
    "        target_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=targets, logits=logits))\n",
    "        correct = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        return target_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incentive function inputs weights, outputs revenue.\n",
    "# This the most basic, just takes the inloop weight as your score\n",
    "def incentive_fn(weights, hparams):\n",
    "    weights = tf.linalg.normalize(weights)\n",
    "    return tf.slice(weights, [0], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(hparams):    \n",
    "    x_inputs = tf.placeholder(\"float\", [None, hparams.n_inputs], 'inputs')\n",
    "    y_targets = tf.placeholder(\"float\", [None, hparams.n_targets], 'targets')    \n",
    "    \n",
    "    # Sparsely gated mixture of experts with choice k. Produces an importance score \n",
    "    # for each x_input then chooses the topk. These children recieve the outgoing query.\n",
    "    # expert_inputs is a list of tensors, inputs for each expert.\n",
    "    gates, load = noisy_top_k_gating(x_inputs, hparams.n_experts, train = True, k = hparams.k)\n",
    "    dispatcher = SparseDispatcher(hparams.n_experts, gates)\n",
    "    expert_inputs = dispatcher.dispatch(x_inputs)\n",
    "\n",
    "    # Basic importance scores can attained from the gating network by summing over the importance \n",
    "    # of each example. We choose a 'self-importance' score here which counts as the in loop in our\n",
    "    # incentive function. The network should try to maximize this value.\n",
    "    importance = tf.linalg.normalize(tf.reduce_sum(gates, 0))[0]\n",
    "    self_weight = tf.Variable(tf.constant([1.0]))\n",
    "    weights = tf.linalg.normalize(tf.concat([self_weight, importance], axis=0))[0]\n",
    "    revenue = tf.slice(weights, [0], [1])\n",
    "    \n",
    "    # Dispatch the inputs to the experts. We mask the responses with a faux-bidding system,\n",
    "    # here, we set a mask w.r.t the bids with a hparams.market_shift shifted relu. Bids that\n",
    "    # drop bellow the market shift should zero out.\n",
    "    expert_outputs = []\n",
    "    expert_masks = []\n",
    "    for i in range(hparams.n_experts):\n",
    "        expert_output = expert(i, expert_inputs[i], hparams)\n",
    "        \n",
    "        # Apply mask to the output.\n",
    "        expert_mask = tf.nn.relu(tf.slice(weights, [i], [1]) - hparams.market_shift)\n",
    "        masked_output = expert_mask * expert_output\n",
    "        \n",
    "        expert_masks.append(expert_mask)\n",
    "        expert_outputs.append(masked_output)\n",
    "    expert_masks = tf.concat(expert_masks, axis=0)\n",
    "\n",
    "    \n",
    "    # Combine the expert_inputs.\n",
    "    embedding = dispatcher.combine(expert_outputs)\n",
    "        \n",
    "    # Loss and accuracy stuff.\n",
    "    loss, accuracy = target_loss(embedding, y_targets, hparams)\n",
    "    \n",
    "    # Run the step: optimize for loss and revenue. \n",
    "    train_step = tf.train.AdamOptimizer(hparams.learning_rate).minimize(loss - revenue)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'revenue': revenue,\n",
    "        'accuracy': accuracy,\n",
    "        'importance': importance,\n",
    "        'weights': weights,\n",
    "        'masks': expert_masks,\n",
    "    }\n",
    "    return train_step, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:484: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:486: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:496: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:498: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:501: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:383: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:246: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:247: The name tf.unsorted_segment_sum is deprecated. Please use tf.math.unsorted_segment_sum instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/const/Workspace/2019/GradientBidding/utils.py:843: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "loss:  1.8384356\n",
      "revenue:  [0.70746005]\n",
      "accuracy:  0.4609375\n",
      "importance:  [0.48973477 0.6229136  0.6100317 ]\n",
      "weights:  [0.70746005 0.34612164 0.44024622 0.4311419 ]\n",
      "masks:  [0.50746006 0.14612164 0.24024622]\n",
      "-\n",
      "loss:  0.34438166\n",
      "revenue:  [0.74051046]\n",
      "accuracy:  0.91015625\n",
      "importance:  [0.531048   0.82449776 0.19542626]\n",
      "weights:  [0.74051046 0.3568881  0.5540995  0.13133521]\n",
      "masks:  [0.5405105  0.15688808 0.3540995 ]\n",
      "-\n",
      "loss:  0.18313497\n",
      "revenue:  [0.76646674]\n",
      "accuracy:  0.9375\n",
      "importance:  [0.56774634 0.7810686  0.2599921 ]\n",
      "weights:  [0.76646674 0.36465442 0.5016679  0.16698878]\n",
      "masks:  [0.56646675 0.16465442 0.30166793]\n",
      "-\n",
      "loss:  0.1255266\n",
      "revenue:  [0.7877404]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.5821953 0.7429029 0.3303696]\n",
      "weights:  [0.7877404  0.3586366  0.45763367 0.2035101 ]\n",
      "masks:  [0.5877404  0.15863658 0.2576337 ]\n",
      "-\n",
      "loss:  0.2458312\n",
      "revenue:  [0.805326]\n",
      "accuracy:  0.9375\n",
      "importance:  [0.55986    0.78749204 0.25770774]\n",
      "weights:  [0.805326   0.33190292 0.4668505  0.1527774 ]\n",
      "masks:  [0.605326   0.13190292 0.26685047]\n",
      "-\n",
      "loss:  0.11728352\n",
      "revenue:  [0.8200828]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.6173663  0.72809047 0.2978982 ]\n",
      "weights:  [0.8200828  0.35328463 0.41664594 0.17047068]\n",
      "masks:  [0.6200828  0.15328462 0.21664594]\n",
      "-\n",
      "loss:  0.112761065\n",
      "revenue:  [0.83310163]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.61765736 0.7362185  0.27655327]\n",
      "weights:  [0.83310163 0.34163857 0.40721712 0.15296713]\n",
      "masks:  [0.63310164 0.14163856 0.20721711]\n",
      "-\n",
      "loss:  0.1419976\n",
      "revenue:  [0.84407914]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.59043175 0.7268842  0.3507562 ]\n",
      "weights:  [0.84407914 0.31660047 0.3897688  0.188082  ]\n",
      "masks:  [0.64407915 0.11660047 0.1897688 ]\n",
      "-\n",
      "loss:  0.1753139\n",
      "revenue:  [0.853416]\n",
      "accuracy:  0.94140625\n",
      "importance:  [0.7063048  0.64732575 0.2865362 ]\n",
      "weights:  [0.853416   0.3681475  0.33740583 0.14935136]\n",
      "masks:  [0.65341604 0.16814749 0.13740583]\n",
      "-\n",
      "loss:  0.1333942\n",
      "revenue:  [0.8619876]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.6112971 0.716845  0.3353344]\n",
      "weights:  [0.8619876  0.30988443 0.36338976 0.16999084]\n",
      "masks:  [0.6619876  0.10988443 0.16338976]\n",
      "-\n",
      "loss:  0.112275004\n",
      "revenue:  [0.86949295]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.59933615 0.7301529  0.32813543]\n",
      "weights:  [0.86949295 0.29603937 0.36065573 0.16208102]\n",
      "masks:  [0.66949296 0.09603937 0.16065572]\n",
      "-\n",
      "loss:  0.07855536\n",
      "revenue:  [0.87610036]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.5645261 0.7545568 0.3345958]\n",
      "weights:  [0.87610036 0.27217433 0.3637936  0.16131829]\n",
      "masks:  [0.6761004  0.07217433 0.16379361]\n",
      "-\n",
      "loss:  0.111297734\n",
      "revenue:  [0.8820366]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.60453445 0.71094906 0.35929027]\n",
      "weights:  [0.8820366  0.28484508 0.33498564 0.16929072]\n",
      "masks:  [0.68203664 0.08484508 0.13498564]\n",
      "-\n",
      "loss:  0.057301994\n",
      "revenue:  [0.8873487]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.6416426  0.7061444  0.29942414]\n",
      "weights:  [0.8873487  0.29586074 0.32560247 0.13806418]\n",
      "masks:  [0.6873487  0.09586073 0.12560247]\n",
      "-\n",
      "loss:  0.13549067\n",
      "revenue:  [0.89171416]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.64161104 0.6886262  0.33783013]\n",
      "weights:  [0.89171416 0.29039243 0.31167147 0.15290153]\n",
      "masks:  [0.69171417 0.09039243 0.11167146]\n",
      "-\n",
      "loss:  0.23937649\n",
      "revenue:  [0.8962223]\n",
      "accuracy:  0.9453125\n",
      "importance:  [0.69227445 0.6681939  0.27253076]\n",
      "weights:  [0.8962223  0.30709648 0.2964142  0.12089603]\n",
      "masks:  [0.6962223  0.10709648 0.09641419]\n",
      "-\n",
      "loss:  0.11689493\n",
      "revenue:  [0.90028507]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.6140081  0.7080004  0.34889767]\n",
      "weights:  [0.90028507 0.26727825 0.30819318 0.15187544]\n",
      "masks:  [0.7002851  0.06727825 0.10819317]\n",
      "-\n",
      "loss:  0.19432013\n",
      "revenue:  [0.90364736]\n",
      "accuracy:  0.953125\n",
      "importance:  [0.65592444 0.68549806 0.31599957]\n",
      "weights:  [0.90364736 0.28091747 0.29358318 0.13533542]\n",
      "masks:  [0.7036474  0.08091746 0.09358318]\n",
      "-\n",
      "loss:  0.10662933\n",
      "revenue:  [0.9069496]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.6459402 0.7180269 0.259227 ]\n",
      "weights:  [0.9069496  0.27209523 0.30246097 0.10919654]\n",
      "masks:  [0.7069496  0.07209523 0.10246097]\n",
      "-\n",
      "loss:  0.16992289\n",
      "revenue:  [0.91000414]\n",
      "accuracy:  0.94921875\n",
      "importance:  [0.6765489  0.6643171  0.31774887]\n",
      "weights:  [0.91000414 0.28049663 0.27542534 0.13173844]\n",
      "masks:  [0.71000415 0.08049662 0.07542534]\n",
      "-\n",
      "loss:  0.121338986\n",
      "revenue:  [0.91209936]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.579425  0.7716361 0.262382 ]\n",
      "weights:  [0.91209936 0.23754646 0.31634712 0.10756856]\n",
      "masks:  [0.7120994  0.03754646 0.11634712]\n",
      "-\n",
      "loss:  0.09706397\n",
      "revenue:  [0.91364783]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.63628227 0.69352406 0.33788934]\n",
      "weights:  [0.91364783 0.25865299 0.28192216 0.13735427]\n",
      "masks:  [0.71364784 0.05865298 0.08192216]\n",
      "-\n",
      "loss:  0.12459071\n",
      "revenue:  [0.9161452]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.66190803 0.6683939  0.339304  ]\n",
      "weights:  [0.9161452  0.2653236  0.26792344 0.13600886]\n",
      "masks:  [0.7161452  0.06532361 0.06792344]\n",
      "-\n",
      "loss:  0.11948491\n",
      "revenue:  [0.91823643]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.60115844 0.7198435  0.34703562]\n",
      "weights:  [0.91823643 0.23807828 0.28508145 0.13743739]\n",
      "masks:  [0.71823645 0.03807828 0.08508144]\n",
      "-\n",
      "loss:  0.07253855\n",
      "revenue:  [0.9190315]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.66856223 0.69867915 0.2546998 ]\n",
      "weights:  [0.9190315  0.26353672 0.27540836 0.10039866]\n",
      "masks:  [0.7190315  0.06353672 0.07540835]\n",
      "-\n",
      "loss:  0.12611972\n",
      "revenue:  [0.9210563]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.6520114  0.70527804 0.27832347]\n",
      "weights:  [0.9210563  0.25391254 0.27465615 0.1083874 ]\n",
      "masks:  [0.7210563  0.05391254 0.07465614]\n",
      "-\n",
      "loss:  0.07421975\n",
      "revenue:  [0.92276675]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.6422662  0.7035724  0.30410504]\n",
      "weights:  [0.92276675 0.24750303 0.2711279  0.11718959]\n",
      "masks:  [0.72276676 0.04750302 0.07112791]\n",
      "-\n",
      "loss:  0.116564274\n",
      "revenue:  [0.9244309]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.7333563  0.6286728  0.25876486]\n",
      "weights:  [0.9244309  0.2796651  0.2397441  0.09867987]\n",
      "masks:  [0.7244309  0.07966511 0.03974409]\n",
      "-\n",
      "loss:  0.07167561\n",
      "revenue:  [0.92579]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.7074626  0.66405964 0.24191168]\n",
      "weights:  [0.92579    0.26744786 0.2510399  0.09145185]\n",
      "masks:  [0.72579    0.06744786 0.05103989]\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.09206778\n",
      "revenue:  [0.9271562]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.66779685 0.674556   0.31467697]\n",
      "weights:  [0.9271562  0.2502068  0.25273928 0.11790159]\n",
      "masks:  [0.7271562  0.0502068  0.05273928]\n",
      "-\n",
      "loss:  0.11937548\n",
      "revenue:  [0.9283053]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.65988934 0.68136275 0.31668735]\n",
      "weights:  [0.9283053  0.24535926 0.25334346 0.1177503 ]\n",
      "masks:  [0.72830534 0.04535925 0.05334346]\n",
      "-\n",
      "loss:  0.055246532\n",
      "revenue:  [0.92831767]\n",
      "accuracy:  0.98828125\n",
      "importance:  [0.6555793  0.69668967 0.29127207]\n",
      "weights:  [0.92831767 0.24373652 0.25902086 0.10829146]\n",
      "masks:  [0.7283177  0.04373652 0.05902086]\n",
      "-\n",
      "loss:  0.06056623\n",
      "revenue:  [0.9292525]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.6328451  0.72911555 0.2605716 ]\n",
      "weights:  [0.9292525  0.23380159 0.26936823 0.09626693]\n",
      "masks:  [0.7292525  0.03380159 0.06936823]\n",
      "-\n",
      "loss:  0.10721418\n",
      "revenue:  [0.9298683]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.72065014 0.63846797 0.27022588]\n",
      "weights:  [0.9298683  0.26512188 0.23488766 0.09941411]\n",
      "masks:  [0.7298683  0.06512187 0.03488766]\n",
      "-\n",
      "loss:  0.10543006\n",
      "revenue:  [0.9301315]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.6937703  0.6854654  0.22095275]\n",
      "weights:  [0.9301315  0.25477108 0.2517213  0.08113978]\n",
      "masks:  [0.7301315  0.05477108 0.05172129]\n",
      "-\n",
      "loss:  0.04573022\n",
      "revenue:  [0.9310142]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.7013959  0.6686452  0.24689564]\n",
      "weights:  [0.9310142  0.2559975  0.24404407 0.09011269]\n",
      "masks:  [0.7310142  0.05599751 0.04404406]\n",
      "-\n",
      "loss:  0.04908303\n",
      "revenue:  [0.93137413]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.6568686  0.717456   0.23190656]\n",
      "weights:  [0.93137413 0.23914185 0.2611995  0.08442871]\n",
      "masks:  [0.73137414 0.03914185 0.0611995 ]\n",
      "-\n",
      "loss:  0.12122077\n",
      "revenue:  [0.9310157]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.6679319  0.7182357  0.19494729]\n",
      "weights:  [0.9310157  0.24378128 0.2621411  0.07115171]\n",
      "masks:  [0.7310157  0.04378128 0.06214111]\n",
      "-\n",
      "loss:  0.047466174\n",
      "revenue:  [0.9315939]\n",
      "accuracy:  0.98828125\n",
      "importance:  [0.6802981 0.6846944 0.2615109]\n",
      "weights:  [0.9315939  0.24728882 0.24888688 0.09505939]\n",
      "masks:  [0.7315939  0.04728882 0.04888688]\n",
      "-\n",
      "loss:  0.061168447\n",
      "revenue:  [0.9326082]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.69220126 0.68466103 0.2282471 ]\n",
      "weights:  [0.9326082  0.24980874 0.24708754 0.08237217]\n",
      "masks:  [0.7326082  0.04980874 0.04708754]\n",
      "-\n",
      "loss:  0.26286918\n",
      "revenue:  [0.93230706]\n",
      "accuracy:  0.93359375\n",
      "importance:  [0.83457404 0.51993984 0.18206792]\n",
      "weights:  [0.93230706 0.30183852 0.18804547 0.0658481 ]\n",
      "masks:  [0.7323071  0.10183851 0.        ]\n",
      "-\n",
      "loss:  0.16241959\n",
      "revenue:  [0.93251574]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.7410212  0.6515178  0.16251819]\n",
      "weights:  [0.93251574 0.26760465 0.23528232 0.05869012]\n",
      "masks:  [0.73251575 0.06760465 0.03528231]\n",
      "-\n",
      "loss:  0.09415795\n",
      "revenue:  [0.9330311]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.7643912  0.60568786 0.22101647]\n",
      "weights:  [0.9330311  0.27502462 0.21792386 0.07952076]\n",
      "masks:  [0.7330311  0.07502462 0.01792386]\n",
      "-\n",
      "loss:  0.045298804\n",
      "revenue:  [0.9330225]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.6820469  0.70043814 0.21023455]\n",
      "weights:  [0.9330225  0.24541278 0.25203028 0.07564618]\n",
      "masks:  [0.7330225  0.04541278 0.05203028]\n",
      "-\n",
      "loss:  0.074416816\n",
      "revenue:  [0.9333411]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.69083786 0.6839136  0.23453209]\n",
      "weights:  [0.9333411  0.2480045  0.24551874 0.08419488]\n",
      "masks:  [0.7333411  0.04800449 0.04551874]\n",
      "-\n",
      "loss:  0.07246214\n",
      "revenue:  [0.9341984]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.7105047  0.66719747 0.22367527]\n",
      "weights:  [0.9341984  0.25347537 0.23802535 0.07979704]\n",
      "masks:  [0.7341984  0.05347537 0.03802535]\n",
      "-\n",
      "loss:  0.108141676\n",
      "revenue:  [0.9336024]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.7025952  0.67010087 0.23942581]\n",
      "weights:  [0.9336024  0.25174743 0.24010438 0.08578885]\n",
      "masks:  [0.7336024  0.05174743 0.04010437]\n",
      "-\n",
      "loss:  0.14515713\n",
      "revenue:  [0.93324023]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.615218   0.75018424 0.24234349]\n",
      "weights:  [0.93324023 0.22101873 0.26950574 0.08706256]\n",
      "masks:  [0.73324025 0.02101873 0.06950574]\n",
      "-\n",
      "loss:  0.061830156\n",
      "revenue:  [0.9337804]\n",
      "accuracy:  0.98828125\n",
      "importance:  [0.71390265 0.65993416 0.2341581 ]\n",
      "weights:  [0.9337804  0.25546774 0.2361553  0.08379272]\n",
      "masks:  [0.7337804  0.05546774 0.0361553 ]\n",
      "-\n",
      "loss:  0.13714243\n",
      "revenue:  [0.9344993]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.66071165 0.713157   0.23423731]\n",
      "weights:  [0.9344993  0.23519023 0.25385895 0.08338029]\n",
      "masks:  [0.73449934 0.03519022 0.05385895]\n",
      "-\n",
      "loss:  0.09527935\n",
      "revenue:  [0.9344729]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.62513953 0.76677233 0.14581102]\n",
      "weights:  [0.9344729  0.2225712  0.27299735 0.05191374]\n",
      "masks:  [0.73447293 0.02257119 0.07299735]\n",
      "-\n",
      "loss:  0.06147316\n",
      "revenue:  [0.9343488]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.64391917 0.73961544 0.19579886]\n",
      "weights:  [0.9343488  0.22946694 0.26356927 0.06977486]\n",
      "masks:  [0.73434883 0.02946694 0.06356926]\n",
      "-\n",
      "loss:  0.06674241\n",
      "revenue:  [0.9345839]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.67240465 0.71288115 0.19917947]\n",
      "weights:  [0.9345839  0.23920302 0.25360224 0.07085664]\n",
      "masks:  [0.7345839  0.03920302 0.05360223]\n",
      "-\n",
      "loss:  0.09886618\n",
      "revenue:  [0.9353555]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.67802066 0.7051782  0.2073928 ]\n",
      "weights:  [0.9353555  0.23982213 0.249428   0.07335674]\n",
      "masks:  [0.7353555  0.03982213 0.049428  ]\n",
      "-\n",
      "loss:  0.03043194\n",
      "revenue:  [0.9357231]\n",
      "accuracy:  0.9921875\n",
      "importance:  [0.6752048  0.70185536 0.22693028]\n",
      "weights:  [0.9357231  0.23816869 0.24756928 0.08004636]\n",
      "masks:  [0.73572314 0.03816868 0.04756927]\n",
      "-\n",
      "loss:  0.11720802\n",
      "revenue:  [0.93568945]\n",
      "accuracy:  0.94140625\n",
      "importance:  [0.67220485 0.7145052  0.19396642]\n",
      "weights:  [0.93568945 0.23717044 0.25209504 0.06843614]\n",
      "masks:  [0.73568946 0.03717044 0.05209504]\n",
      "-\n",
      "loss:  0.046798036\n",
      "revenue:  [0.93441314]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.7183632  0.6612567  0.21608765]\n",
      "weights:  [0.93441314 0.25587454 0.2355337  0.07696848]\n",
      "masks:  [0.73441315 0.05587454 0.0355337 ]\n",
      "-\n",
      "loss:  0.0625291\n",
      "revenue:  [0.93526936]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.6906147  0.70063335 0.17934416]\n",
      "weights:  [0.93526936 0.2444339  0.24797985 0.06347648]\n",
      "masks:  [0.73526937 0.04443389 0.04797985]\n",
      "-\n",
      "loss:  0.08567371\n",
      "revenue:  [0.93514407]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.7161795  0.66564494 0.20977053]\n",
      "weights:  [0.93514407 0.25371924 0.2358165  0.07431492]\n",
      "masks:  [0.7351441  0.05371924 0.03581649]\n",
      "-\n",
      "loss:  0.07999948\n",
      "revenue:  [0.93579715]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.7257998  0.66708314 0.16797197]\n",
      "weights:  [0.93579715 0.25587276 0.23517285 0.05921667]\n",
      "masks:  [0.73579717 0.05587275 0.03517285]\n",
      "-\n",
      "loss:  0.103144124\n",
      "revenue:  [0.9361993]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.66748154 0.71236295 0.21681224]\n",
      "weights:  [0.9361993  0.23459959 0.25037405 0.07620295]\n",
      "masks:  [0.7361993  0.03459959 0.05037405]\n",
      "-\n",
      "loss:  0.13977644\n",
      "revenue:  [0.93592286]\n",
      "accuracy:  0.96484375\n",
      "importance:  [0.720527   0.67461354 0.16042867]\n",
      "weights:  [0.93592286 0.25377327 0.23760231 0.05650379]\n",
      "masks:  [0.7359229  0.05377327 0.03760231]\n",
      "-\n",
      "loss:  0.068809465\n",
      "revenue:  [0.9361801]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.6631396  0.7287961  0.17059337]\n",
      "weights:  [0.9361801  0.23310724 0.25618687 0.05996709]\n",
      "masks:  [0.7361801  0.03310724 0.05618687]\n",
      "-\n",
      "loss:  0.059699703\n",
      "revenue:  [0.93591803]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.64167875 0.73194265 0.22914703]\n",
      "weights:  [0.93591803 0.2260107  0.25780326 0.08070967]\n",
      "masks:  [0.73591805 0.02601069 0.05780326]\n",
      "-\n",
      "loss:  0.027208097\n",
      "revenue:  [0.93635166]\n",
      "accuracy:  0.99609375\n",
      "importance:  [0.7496323  0.6403602  0.16730295]\n",
      "weights:  [0.93635166 0.26316854 0.22480708 0.05873396]\n",
      "masks:  [0.73635167 0.06316854 0.02480708]\n",
      "-\n",
      "loss:  0.06464466\n",
      "revenue:  [0.9364369]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.7114981  0.67419285 0.19807696]\n",
      "weights:  [0.9364369  0.24961922 0.23653118 0.06949255]\n",
      "masks:  [0.7364369  0.04961921 0.03653118]\n",
      "-\n",
      "loss:  0.30421174\n",
      "revenue:  [0.936477]\n",
      "accuracy:  0.93359375\n",
      "importance:  [0.86646765 0.47369197 0.15763775]\n",
      "weights:  [0.936477   0.30389532 0.1661375  0.05528813]\n",
      "masks:  [0.736477   0.10389532 0.        ]\n",
      "-\n",
      "loss:  0.16224565\n",
      "revenue:  [0.9365271]\n",
      "accuracy:  0.94140625\n",
      "importance:  [0.87773275 0.42345908 0.22420461]\n",
      "weights:  [0.9365271  0.30772886 0.14846271 0.07860506]\n",
      "masks:  [0.7365271  0.10772885 0.        ]\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.1434359\n",
      "revenue:  [0.9377591]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.85080904 0.49539033 0.17524987]\n",
      "weights:  [0.9377591  0.29547435 0.1720423  0.06086189]\n",
      "masks:  [0.7377591  0.09547435 0.        ]\n",
      "-\n",
      "loss:  0.1352494\n",
      "revenue:  [0.93788004]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.83523214 0.53616846 0.12210899]\n",
      "weights:  [0.93788004 0.28979197 0.1860289  0.04236691]\n",
      "masks:  [0.73788005 0.08979197 0.        ]\n",
      "-\n",
      "loss:  0.18740657\n",
      "revenue:  [0.9374582]\n",
      "accuracy:  0.9453125\n",
      "importance:  [0.8147385  0.5654317  0.12840565]\n",
      "weights:  [0.9374582  0.28360865 0.1968255  0.04469772]\n",
      "masks:  [0.7374582  0.08360864 0.        ]\n",
      "-\n",
      "loss:  0.026457489\n",
      "revenue:  [0.93757105]\n",
      "accuracy:  0.99609375\n",
      "importance:  [0.7115098  0.681526   0.17110305]\n",
      "weights:  [0.93757105 0.24745871 0.23703054 0.05950858]\n",
      "masks:  [0.73757106 0.04745871 0.03703053]\n",
      "-\n",
      "loss:  0.0700033\n",
      "revenue:  [0.9378682]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.70942134 0.6839412  0.17013498]\n",
      "weights:  [0.9378682  0.2461632  0.23732181 0.0590354 ]\n",
      "masks:  [0.7378682  0.0461632  0.03732181]\n",
      "-\n",
      "loss:  0.049046904\n",
      "revenue:  [0.9374951]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.73899555 0.6376058  0.21758793]\n",
      "weights:  [0.9374951  0.2571694  0.22188592 0.0757203 ]\n",
      "masks:  [0.7374951  0.05716939 0.02188592]\n",
      "-\n",
      "loss:  0.1483109\n",
      "revenue:  [0.9374581]\n",
      "accuracy:  0.953125\n",
      "importance:  [0.8232593  0.5378821  0.18145798]\n",
      "weights:  [0.9374581  0.28657496 0.1872357  0.06316517]\n",
      "masks:  [0.7374581  0.08657496 0.        ]\n",
      "-\n",
      "loss:  0.038002297\n",
      "revenue:  [0.9378938]\n",
      "accuracy:  0.98828125\n",
      "importance:  [0.6920856  0.70520955 0.15393788]\n",
      "weights:  [0.9378938  0.2401001  0.24465309 0.05340452]\n",
      "masks:  [0.7378938  0.0401001  0.04465309]\n",
      "-\n",
      "loss:  0.082672216\n",
      "revenue:  [0.9381089]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.6753439 0.7186458 0.1657072]\n",
      "weights:  [0.9381089  0.23389877 0.24889599 0.05739108]\n",
      "masks:  [0.73810893 0.03389877 0.04889598]\n",
      "-\n",
      "loss:  0.11033838\n",
      "revenue:  [0.9381263]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.66950214 0.7122711  0.21080041]\n",
      "weights:  [0.9381263  0.23184407 0.24665466 0.07299875]\n",
      "masks:  [0.73812634 0.03184406 0.04665466]\n",
      "-\n",
      "loss:  0.07660085\n",
      "revenue:  [0.93849146]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.67918295 0.7137227  0.17120273]\n",
      "weights:  [0.93849146 0.23452346 0.24645013 0.05911671]\n",
      "masks:  [0.7384915  0.03452346 0.04645012]\n",
      "-\n",
      "loss:  0.05048685\n",
      "revenue:  [0.9388176]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.70569324 0.67450804 0.21687786]\n",
      "weights:  [0.9388176  0.24305111 0.23231047 0.07469592]\n",
      "masks:  [0.73881763 0.04305111 0.03231047]\n",
      "-\n",
      "loss:  0.1538054\n",
      "revenue:  [0.93696886]\n",
      "accuracy:  0.94140625\n",
      "importance:  [0.9709302  0.2243386  0.08346637]\n",
      "weights:  [0.93696886 0.33925557 0.07838681 0.02916423]\n",
      "masks:  [0.7369689  0.13925557 0.        ]\n",
      "-\n",
      "loss:  0.14292838\n",
      "revenue:  [0.93764687]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.9128801  0.36278585 0.18717992]\n",
      "weights:  [0.93764687 0.31730756 0.12610056 0.06506178]\n",
      "masks:  [0.7376469  0.11730756 0.        ]\n",
      "-\n",
      "loss:  0.10823503\n",
      "revenue:  [0.9388667]\n",
      "accuracy:  0.94921875\n",
      "importance:  [0.8832898  0.42669806 0.19423696]\n",
      "weights:  [0.9388667  0.30409986 0.14690402 0.06687209]\n",
      "masks:  [0.7388667  0.10409985 0.        ]\n",
      "-\n",
      "loss:  0.13318956\n",
      "revenue:  [0.9398483]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.83796036 0.52440244 0.1510777 ]\n",
      "weights:  [0.9398483  0.2862407  0.17913176 0.05160696]\n",
      "masks:  [0.7398483  0.08624069 0.        ]\n",
      "-\n",
      "loss:  0.06761978\n",
      "revenue:  [0.9397534]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.70903516 0.68975556 0.14665069]\n",
      "weights:  [0.9397534  0.24238603 0.23579523 0.05013302]\n",
      "masks:  [0.7397534  0.04238603 0.03579523]\n",
      "-\n",
      "loss:  0.09238246\n",
      "revenue:  [0.93929416]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.6860644  0.7137847  0.14080809]\n",
      "weights:  [0.93929416 0.23539755 0.24490872 0.04831307]\n",
      "masks:  [0.7392942  0.03539754 0.04490872]\n",
      "-\n",
      "loss:  0.072649576\n",
      "revenue:  [0.93935037]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.7031688 0.689794  0.1724471]\n",
      "weights:  [0.93935037 0.24115789 0.2365709  0.05914224]\n",
      "masks:  [0.7393504  0.04115789 0.03657089]\n",
      "-\n",
      "loss:  0.0825016\n",
      "revenue:  [0.93908876]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.8975633  0.4179026  0.14048992]\n",
      "weights:  [0.93908876 0.3084698  0.14362256 0.04828284]\n",
      "masks:  [0.7390888 0.1084698 0.       ]\n",
      "-\n",
      "loss:  0.12566194\n",
      "revenue:  [0.94002545]\n",
      "accuracy:  0.96875\n",
      "importance:  [0.845448   0.5127508  0.14934623]\n",
      "weights:  [0.94002545 0.2883859  0.17490147 0.05094263]\n",
      "masks:  [0.74002546 0.08838589 0.        ]\n",
      "-\n",
      "loss:  0.040340044\n",
      "revenue:  [0.9402765]\n",
      "accuracy:  0.984375\n",
      "importance:  [0.73704493 0.65914387 0.1493121 ]\n",
      "weights:  [0.9402765  0.2508987  0.22438025 0.05082758]\n",
      "masks:  [0.7402765  0.05089869 0.02438025]\n",
      "-\n",
      "loss:  0.09849268\n",
      "revenue:  [0.939903]\n",
      "accuracy:  0.9609375\n",
      "importance:  [0.7217792  0.67916393 0.13330856]\n",
      "weights:  [0.939903   0.24644533 0.2318947  0.04551706]\n",
      "masks:  [0.73990303 0.04644533 0.0318947 ]\n",
      "-\n",
      "loss:  0.06179246\n",
      "revenue:  [0.93988794]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.6671457 0.7307346 0.1447188]\n",
      "weights:  [0.93988794 0.22781909 0.24953361 0.04941904]\n",
      "masks:  [0.73988795 0.02781908 0.04953361]\n",
      "-\n",
      "loss:  0.18642458\n",
      "revenue:  [0.93933415]\n",
      "accuracy:  0.9453125\n",
      "importance:  [0.9125174  0.38201058 0.14621894]\n",
      "weights:  [0.93933415 0.3129965  0.1310309  0.05015358]\n",
      "masks:  [0.73933417 0.1129965  0.        ]\n",
      "-\n",
      "loss:  0.11708365\n",
      "revenue:  [0.9400545]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.7080006  0.6969782  0.11382633]\n",
      "weights:  [0.9400545  0.24144529 0.2376864  0.03881752]\n",
      "masks:  [0.7400545  0.04144529 0.03768639]\n",
      "-\n",
      "loss:  0.10459344\n",
      "revenue:  [0.93989164]\n",
      "accuracy:  0.97265625\n",
      "importance:  [0.75664485 0.6480745  0.0865329 ]\n",
      "weights:  [0.93989164 0.25837368 0.22129986 0.02954864]\n",
      "masks:  [0.73989165 0.05837367 0.02129985]\n",
      "-\n",
      "loss:  0.07418416\n",
      "revenue:  [0.9398792]\n",
      "accuracy:  0.9765625\n",
      "importance:  [0.72185904 0.67588276 0.14866763]\n",
      "weights:  [0.9398792  0.24651988 0.23081866 0.05077103]\n",
      "masks:  [0.7398792  0.04651988 0.03081866]\n",
      "-\n",
      "loss:  0.08383167\n",
      "revenue:  [0.9400688]\n",
      "accuracy:  0.98046875\n",
      "importance:  [0.72156477 0.6725828  0.16424596]\n",
      "weights:  [0.9400688  0.24604255 0.22934045 0.05600536]\n",
      "masks:  [0.7400688  0.04604255 0.02934045]\n",
      "-\n",
      "loss:  0.15894951\n",
      "revenue:  [0.9394088]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.918696   0.37009764 0.1379328 ]\n",
      "weights:  [0.9394088  0.31492776 0.12686898 0.04728318]\n",
      "masks:  [0.7394088  0.11492775 0.        ]\n",
      "-\n",
      "loss:  0.10711551\n",
      "revenue:  [0.94081134]\n",
      "accuracy:  0.95703125\n",
      "importance:  [0.7373999  0.65126604 0.17914793]\n",
      "weights:  [0.94081134 0.24992749 0.22073409 0.06071874]\n",
      "masks:  [0.74081135 0.04992749 0.02073409]\n",
      "-\n",
      "loss:  0.04458772\n",
      "revenue:  [0.9412088]\n",
      "accuracy:  0.98828125\n",
      "importance:  [0.74434894 0.6577774  0.11521066]\n",
      "weights:  [0.9412088  0.25146013 0.22221406 0.03892111]\n",
      "masks:  [0.7412088  0.05146013 0.02221406]\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "hparams = types.SimpleNamespace( \n",
    "    n_inputs = 784,\n",
    "    n_targets = 10,\n",
    "    k = 3,\n",
    "    n_experts = 3,\n",
    "    e_layers = 2,\n",
    "    e_hidden = 256,\n",
    "    n_embedding = 256,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    n_iterations = 10000,\n",
    "    n_print = 100,\n",
    "    market_shift = 0.2,\n",
    ")\n",
    "\n",
    "graph = tf.Graph()\n",
    "session = tf.Session(graph=graph)\n",
    "with graph.as_default():\n",
    "    train_step, metrics = model_fn(hparams)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(hparams.n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(hparams.batch_size)\n",
    "    feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
    "    session.run(train_step, feeds)\n",
    "\n",
    "    if i % hparams.n_print == 0:\n",
    "        feeds = {'inputs:0': batch_x, 'targets:0': batch_y}\n",
    "        train_metrics = session.run(metrics, feeds)\n",
    "        for key in train_metrics:\n",
    "            print (str(key) + \":  \" + str(train_metrics[key]))\n",
    "        print ('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
